{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import everything you need (e.g., model, dataset, etc.)\n",
    "# 2. Use Random Search to find the best hyperparams(e.g., batch_size, augmentation, optimizer, loss_fn, etc.)\n",
    "# 3. Report the best train configuration\n",
    "# 4. Save the best values (for hyperparams)\n",
    "# 5. Use the found values in \"train.ipynb\" to train the model with them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Cells for GoogleColab\n",
    "> This way we can execute our code from github without any hassles, just:\n",
    ">> 1. add all the packages needed (that is not in Colab) in \"requirements.txt\"\n",
    ">> 2. The github repo must be public, if the Colab account (e.g., <golab_pro_owner>@gmail.com) has not been granted access to that repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mount the Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the Github Repo\n",
    "# !git clone https://github.com/tekboart/semantic-segmentaion-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the repo's main dir\n",
    "# %cd semantic-segmentaion-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow Tensorboard to write to the tmp directory:\n",
    "# !export TMPDIR=/tmp/$USER; mkdir -p $TMPDIR; tensorboard --logdir=~/ray_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tekboart/.local/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/tekboart/.local/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "2023-07-14 11:54:24.069911: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 11:54:24.748972: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# reload modules\n",
    "from importlib import reload\n",
    "\n",
    "# load pretrained segmentation models (written in pytorch)\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torchvision\n",
    "from torchviz import make_dot\n",
    "import torchvision.transforms.v2 as TF\n",
    "\n",
    "# torchmetrics\n",
    "from torchmetrics.classification import Dice, BinaryJaccardIndex\n",
    "\n",
    "# Ray Tune\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "# Serialize/Deserialize Json files\n",
    "import json\n",
    "\n",
    "# Data Augmentation\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# get data/time with desired format\n",
    "from datetime import datetime\n",
    "\n",
    "time_format = \"%Y.%m.%d@%H-%M-%S\"\n",
    "\n",
    "# work with images\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# slice Iterables and turn to GEN\n",
    "from itertools import islice\n",
    "\n",
    "# keep numpy use to a min\n",
    "# as we store our torch.Tensors to GPU Vram but numpy in RAM (it only supports CPU)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# to have a progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# To use pretrained segmentation models (implement in PyTorch)\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "# uncomment if wan't to globally aloow sns to handle plot style\n",
    "# it adds unwanted style (i.e., grid) to .imshow()\n",
    "# so better to use it a context manager to style only what I want\n",
    "# >>> with sns.axes_style('darkgrid'):\n",
    "# >>>     plt.imshow(...)\n",
    "# sns.set_theme(\n",
    "#     context=\"notebook\",\n",
    "#     style=\"darkgrid\",\n",
    "#     palette=\"deep\",\n",
    "#     font=\"sans-serif\",\n",
    "#     font_scale=1,\n",
    "#     color_codes=True,\n",
    "#     rc={'axes.grid': False},\n",
    "# )\n",
    "\n",
    "# OS/File/Path management\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Misc\n",
    "from functools import partial\n",
    "\n",
    "# load my custom Classes/Functions/etc.\n",
    "from utils.training import fit_fn\n",
    "from utils.dataset import get_loaders, SegmentaionDataset\n",
    "from utils.models.unet import UnetScratch\n",
    "from utils.visualization import (\n",
    "    image_mask_plot,\n",
    "    ImageAntiStandardize,\n",
    "    plot_metrics\n",
    ")\n",
    "from utils.metrics import (\n",
    "    AccuracyBinarySegment,\n",
    "    DiceBinarySegment,\n",
    "    JaccardBinarySegment,\n",
    "    PrecisionBinarySegment,\n",
    "    RecallBinarySegment,\n",
    "    F1BinarySegment,\n",
    "    DiceBCELoss,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove sources of non-determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f208ff76d10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use to seed the RNG for all devices (both CPU and CUDA).\n",
    "torch.manual_seed(0)\n",
    "# for custom operators, you might need to set python seed as well:\n",
    "random.seed(0)\n",
    "# If you or any of the libraries you are using rely on NumPy, you can seed the global NumPy RNG with:\n",
    "np.random.seed(0)\n",
    "\n",
    "# configure PyTorch to use deterministic algorithms instead of nondeterministic ones \n",
    "# A CAVEAT: throws an error if an operation is known to be nondeterministic (and without a deterministic alternative).\n",
    "# that is why we used warn_only to avoid raising Error\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "# CUDA convolution determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# -- DataLoader\n",
    "# make it deterministic but allow it to random data order\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "DATA_LOADER_GEN = torch.Generator()\n",
    "DATA_LOADER_GEN.manual_seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Search Hyperparameters Space\n",
    "> that is, the hyperparameters and their correspondign values to search for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Config dict\n",
    "config = {\n",
    "    'lr': tune.loguniform(1e-4, 1e-3),\n",
    "    'scheduler_factor': tune.choice([.5, .3, .1]),\n",
    "    'batch_size': tune.choice([4, 8, 16, 32]),\n",
    "    'image_size': tune.choice([352, 256, 160]),  # sizes must be divisible by 32 \n",
    "    'pretrained_arch': tune.choice([smp.UnetPlusPlus, smp.FPN, smp.DeepLabV3Plus]),\n",
    "    #TODO: Maybe remove ResNet152 as it's both (1) comp expensive and (2) can overfit very easily (considering its #params)\n",
    "    'pretrained_encoder': tune.choice(['mobilenet_v2', 'timm-mobilenetv3_large_100', 'timm-efficientnet-b8']),\n",
    "    # 'loss_fn': tune.choice([nn.BCEWithLogitsLoss(), DiceBCELoss(from_logits=True)]),\n",
    "    # 'train_augmentation': tune.choice([\n",
    "    #     #TODO: As my last model's val & test metrics were very different, then maybe I need stronger augmentations for the model to generalize better.\n",
    "    #     # We didn't included the resize/Flip/etc. that we know would cause no problem. so:\n",
    "    #     # Just use this A.Compose([*hyper_config['train_augmentation'], A.HorizontalFlip(...), A.Resize(..), etc.])\n",
    "    #     [\n",
    "    #         A.Rotate(limit=5, p=0.5),  # Use only when the img_height==img_width\n",
    "    #         A.RandomRotate90(p=0.5),  # Use only when the img_height==img_width\n",
    "    #         A.Transpose(p=0.5),  # Use only when the img_height==img_width\n",
    "    #         # A.CenterCrop(\n",
    "    #             #TODO: Remember to add vars image_height & image_width in the train func\n",
    "    #             # int(0.9 * image_height),\n",
    "    #             # int(0.9 * image_width),\n",
    "    #             # p=0.3,\n",
    "    #         # ),\n",
    "    #         A.ColorJitter(\n",
    "    #             brightness=0.3,\n",
    "    #             contrast=0.05,\n",
    "    #             saturation=0.1,\n",
    "    #             hue=0.05,\n",
    "    #             p=0.8,\n",
    "    #             # always_apply=True,\n",
    "    #         ),\n",
    "    #         A.ImageCompression(quality_lower=90, quality_upper=100, p=0.3),\n",
    "    #         A.RGBShift(\n",
    "    #             r_shift_limit=5,\n",
    "    #             g_shift_limit=5,\n",
    "    #             b_shift_limit=2,\n",
    "    #             p=0.8,\n",
    "    #             # always_apply=True,\n",
    "    #         ),\n",
    "    #     ],\n",
    "    #     [\n",
    "    #         A.Rotate(limit=5, p=0.5),  # Use only when the img_height==img_width\n",
    "    #         A.RandomRotate90(p=0.5),  # Use only when the img_height==img_width\n",
    "    #         A.Transpose(p=0.5),  # Use only when the img_height==img_width\n",
    "    #         A.ColorJitter(\n",
    "    #             brightness=0.3,\n",
    "    #             contrast=0.05,\n",
    "    #             saturation=0.1,\n",
    "    #             hue=0.05,\n",
    "    #             p=0.8,\n",
    "    #             # always_apply=True,\n",
    "    #         ),\n",
    "    #         A.RGBShift(\n",
    "    #             r_shift_limit=5,\n",
    "    #             g_shift_limit=5,\n",
    "    #             b_shift_limit=2,\n",
    "    #             p=0.8,\n",
    "    #             # always_apply=True,\n",
    "    #         ),\n",
    "    #     ],\n",
    "    #     [\n",
    "    #         # means use no fancy Augmentation. Just some flip and 90deg rotations.\n",
    "    #     ]\n",
    "    # ])\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used for calculation (CPU\\Cuda): cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device used for calculation (CPU\\Cuda):\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create The Model Func\n",
    "> Everything needed for trainin a model needs to be within its scope (should not use any var from outside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model_creator_for_hyperserach to create + Compile a model (to be ready to be trained)\n",
    "# TODO: Can I make it reusable for other models as well?\n",
    "# A: I don't think\n",
    "def model_creator(config):\n",
    "    \"\"\"\n",
    "    instantiate + Compile + train (aka .fit()) a network\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hyper_config: dict\n",
    "        Includes all the hyperparmeters needed to be tuned.\n",
    "    \"\"\"\n",
    "    DATA_LOADER_GEN = torch.Generator()\n",
    "    DATA_LOADER_GEN.manual_seed(0)\n",
    "\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    # print(\"Device used for calculation (CPU\\Cuda):\", device)\n",
    "\n",
    "    # Load all the needed variables (Ray Tune asks all the used variables to be inside this func scope)\n",
    "    hyper_params = {\n",
    "        # \"device\": str(device),\n",
    "        \"lr\": 1e-3,\n",
    "        \"lr_finetune\": 1e-4,  # for transfer learning (phase 2) (= lr / 1000)\n",
    "        \"epochs\": 10,  #XXX: Set the #epochs to at least 10 for the real run in Colab\n",
    "        \"epochs_finetune\": 10,  # for transfer learning (phase 2)\n",
    "        \"batch_size\": 16,\n",
    "        \"num_workers\": 2,\n",
    "        # Use Height == Width to use 90-rotations/transpose in data aug\n",
    "        \"image_height\": 352,\n",
    "        \"image_width\": 352,\n",
    "        \"input_channels\": 3,\n",
    "        \"num_classes\": 1,\n",
    "        \"data_format\": \"channels_first\",\n",
    "        \"pin_mem\": True,\n",
    "        \"scheduler_step\": 5,\n",
    "        \"scheduler_factor\": 0.5,\n",
    "        \"scheduler_factor_finetune\": 0.5,  # for transfer learning (phase 2)\n",
    "        \"train_img_dir\": os.path.join(\"data\", \"traincrop\", \"img\"),\n",
    "        \"train_mask_dir\": os.path.join(\"data\", \"traincrop\", \"mask\"),\n",
    "        \"val_img_dir\": os.path.join(\"data\", \"valcrop\", \"img\"),\n",
    "        \"val_mask_dir\": os.path.join(\"data\", \"valcrop\", \"mask\"),\n",
    "        \"test_img_dir\": os.path.join(\"data\", \"testcrop\", \"img\"),\n",
    "        \"test_mask_dir\": os.path.join(\"data\", \"testcrop\", \"mask\"),\n",
    "        \"pretrained_model_encoder\": \"timm-mobilenetv3_large_100\",\n",
    "    }\n",
    "\n",
    "    # Load a Pretrained Model\n",
    "    # TODO: Load the preprocess_fn before, so no need to create it for each run\n",
    "    model_arch = config[\"pretrained_arch\"]\n",
    "\n",
    "    # create the model\n",
    "    model = model_arch(\n",
    "        # choose encoder\n",
    "        encoder_name=config[\"pretrained_encoder\"],\n",
    "        # use `imagenet` pre-trained weights for encoder initialization\n",
    "        encoder_weights=\"imagenet\",\n",
    "        # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        in_channels=hyper_params[\"input_channels\"],\n",
    "        # model output channels (number of classes in your dataset)\n",
    "        classes=hyper_params[\"num_classes\"],\n",
    "    )\n",
    "\n",
    "    preprocess_input = get_preprocessing_fn(\n",
    "        config[\"pretrained_encoder\"], pretrained=\"imagenet\"\n",
    "    )\n",
    "\n",
    "    # Create Data Augmentation\n",
    "    train_transform = A.Compose(\n",
    "        [\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.1),\n",
    "            A.Rotate(limit=5, p=0.5),  # Use only when the img_height==img_width\n",
    "            A.RandomRotate90(p=0.5),  # Use only when the img_height==img_width\n",
    "            A.Transpose(p=0.5),  # Use only when the img_height==img_width\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.0, p=0.5),\n",
    "            A.CenterCrop(\n",
    "                int(0.95 * hyper_params[\"image_height\"]),\n",
    "                int(0.95 * hyper_params[\"image_width\"]),\n",
    "                p=0.3,\n",
    "            ),\n",
    "            A.ColorJitter(\n",
    "                brightness=0.0,\n",
    "                contrast=0.0,\n",
    "                saturation=0.1,\n",
    "                hue=0.05,\n",
    "                p=0.8,\n",
    "            ),\n",
    "            A.ImageCompression(quality_lower=90, quality_upper=100, p=0.1),\n",
    "            A.RGBShift(\n",
    "                r_shift_limit=5,\n",
    "                g_shift_limit=5,\n",
    "                b_shift_limit=2,\n",
    "                p=0.8,\n",
    "            ),\n",
    "            A.Resize(\n",
    "                height=hyper_params[\"image_height\"], width=hyper_params[\"image_width\"]\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # we don't want TTA, just some resize, normalization, etc.\n",
    "    val_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=config[\"image_size\"], width=config[\"image_size\"]),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Create the Datasets\n",
    "    train_ds = SegmentaionDataset(\n",
    "        image_dir=hyper_params[\"train_img_dir\"],\n",
    "        mask_dir=hyper_params[\"train_mask_dir\"],\n",
    "        transform=train_transform,\n",
    "        preprocess_fn=preprocess_input,\n",
    "        mask_suffix=\"\",\n",
    "        subset=[0, 10],\n",
    "    )\n",
    "    val_ds = SegmentaionDataset(\n",
    "        image_dir=hyper_params[\"val_img_dir\"],\n",
    "        mask_dir=hyper_params[\"val_mask_dir\"],\n",
    "        transform=val_transform,\n",
    "        preprocess_fn=preprocess_input,\n",
    "        mask_suffix=\"\",\n",
    "        subset=[0, 5],\n",
    "    )\n",
    "    train_loader, val_loader = get_loaders(\n",
    "        train_ds,\n",
    "        val_ds,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        num_workers=hyper_params[\"num_workers\"],\n",
    "        pin_memory=hyper_params[\"pin_mem\"],\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=DATA_LOADER_GEN,\n",
    "    )\n",
    "\n",
    "    # Define Metrics\n",
    "    metrics = {\n",
    "        \"jaccard (IOU)\": JaccardBinarySegment(from_logits=True),\n",
    "        \"recall\": RecallBinarySegment(from_logits=True),\n",
    "        \"precision\": PrecisionBinarySegment(from_logits=True),\n",
    "        \"dice (F1-Score)\": DiceBinarySegment(from_logits=True),\n",
    "    }\n",
    "\n",
    "    # Define Loss_fn, Optimizer, and Scheduler\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"min\",\n",
    "        factor=config[\"scheduler_factor\"],\n",
    "        # factor=hyper_params[\"scheduler_factor\"],\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        threshold=1e-3,\n",
    "    )\n",
    "\n",
    "    # train the model (and get the history)\n",
    "    # TODO: must change the fit_fn to use session.report(...)\n",
    "    # TODO: use verbose=False to make the output of ray tune clean\n",
    "    history = fit_fn(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        scheduler,\n",
    "        metrics=metrics,\n",
    "        val_loader=val_loader,\n",
    "        epochs=hyper_params[\"epochs\"],\n",
    "        device=device,\n",
    "        ray_tune=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a partial func of the model_creator (using functools.partial)\n",
    "# as we only change the hyperparams of interest for each run of Ray Tune (i.e., hyperparam_tuner)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tuner Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_tuner(\n",
    "    config: dict,\n",
    "    num_samples: int = 10,\n",
    "    max_num_epochs: int = 10,\n",
    "    tune_metric: str = \"val_loss\",\n",
    "    tune_metric_mode: str = \"min\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a model and a set of hyperparameters,\n",
    "    tries to find the best combination and return the best performing model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hyper_config: dict\n",
    "    max_num_epochs: int\n",
    "    num_samples: int\n",
    "        Define the total number of samples/combinatin to use to train the model.\n",
    "        In other words, the number of models to train for finding the best hyperparameters.\n",
    "    tune_metric: str\n",
    "        The name of the metric (e.g., val_loss) by which the performance of mdoels are assessed.\n",
    "    tune_metric_mode: str\n",
    "        Either \"min\" (default) or \"max\", depending on the chosen tune_metric. Specifies whether \"min\" values are desired, or vice versa.\n",
    "    \"\"\"\n",
    "    # use ASHAScheduler to stop training early on if the model's plight is doomed\n",
    "    scheduler_ray = ASHAScheduler(\n",
    "        # metric=\"loss\",  # this is specified in the Tuner's tune.TuneConifg, so only one must be present.\n",
    "        # mode=\"min\",  # this is specified in the Tuner's tune.TuneConifg, so only one must be present.\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "    # method 1 (less control): from Pytorch Tutorials\n",
    "    # results = tune.run(\n",
    "    #     model_creator,\n",
    "    #     resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "    #     config=hyper_config,\n",
    "    #     num_samples=num_samples,\n",
    "    #     scheduler=scheduler_ray,\n",
    "    # )\n",
    "\n",
    "    # method 2 (more control): from Ray Tune official documentaions\n",
    "    tuner = tune.Tuner(\n",
    "        # Use Only CPU\n",
    "        # model_creator,\n",
    "        # Use only GPU\n",
    "        # tune.with_resources(model_creator, {\"gpu\": 1}),\n",
    "        # Use both CPU & GPU --> the numbers define how many model to be trained in parallel\n",
    "        tune.with_resources(model_creator, {\"gpu\": 1, \"cpu\": 0}),  #FIXME: change the \"gpu\" and \"cou\" values for Colab Pro\n",
    "        param_space=config,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            num_samples=num_samples,\n",
    "            metric=tune_metric,\n",
    "            mode=tune_metric_mode,\n",
    "            search_alg=OptunaSearch(),  # Optuna Works better than Random Search (BOn Pytorch official YouTube)\n",
    "            scheduler=scheduler_ray,\n",
    "            chdir_to_trial_dir=False,  # if True (default) the Ray tune will change the current dir, thus no relative path (e.g., path to our data) doesn't work.\n",
    "        ),\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:54:28,509\tINFO worker.py:1636 -- Started a local Ray instance.\n",
      "2023-07-14 11:54:29,821\tINFO tune.py:226 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "/home/tekboart/.local/lib/python3.11/site-packages/ray/tune/search/optuna/optuna_search.py:664: FutureWarning: LogUniformDistribution has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :class:`~optuna.distributions.FloatDistribution` instead.\n",
      "  return ot.distributions.LogUniformDistribution(\n",
      "/home/tekboart/.local/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ('__ref_ph', 'c70cbae7') which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/tekboart/.local/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ('__ref_ph', 'd08b895f') which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "/home/tekboart/.local/lib/python3.11/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains ('__ref_ph', 'c9fd45ce') which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2023-07-14 11:54:29,846] A new study created in memory with name: optuna\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-07-14 11:55:33</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:03.71        </td></tr>\n",
       "<tr><td>Memory:      </td><td>15.7/31.2 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=4<br>Bracket: Iter 8.000: -1.0750046645601592 | Iter 4.000: -2.0302295858661337 | Iter 2.000: -2.5487915674845376 | Iter 1.000: -4.870289921760559<br>Logical resource usage: 0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>model_creator_1614ecc4</td><td style=\"text-align: right;\">           1</td><td>/home/tekboart/ray_results/model_creator_2023-07-14_11-54-26/model_creator_1614ecc4_3_batch_size=4,image_size=352,lr=0.0003,pretrained_arch=ref_ph_c9fd45ce,pretrained_encoder=timm-efficientne_2023-07-14_11-54-49/error.txt</td></tr>\n",
       "<tr><td>model_creator_303487b8</td><td style=\"text-align: right;\">           1</td><td>/home/tekboart/ray_results/model_creator_2023-07-14_11-54-26/model_creator_303487b8_5_batch_size=8,image_size=256,lr=0.0002,pretrained_arch=ref_ph_d08b895f,pretrained_encoder=timm-efficientne_2023-07-14_11-55-01/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  image_size</th><th style=\"text-align: right;\">         lr</th><th>pretrained_arch     </th><th>pretrained_encoder  </th><th style=\"text-align: right;\">  scheduler_factor</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_jaccard (IOU)</th><th style=\"text-align: right;\">  val_recall</th><th style=\"text-align: right;\">  val_precision</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>model_creator_186d809e</td><td>TERMINATED</td><td>192.168.1.103:641971</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         352</td><td style=\"text-align: right;\">0.000701042</td><td>&lt;class &#x27;segment_f240</td><td>timm-mobilenetv_0a80</td><td style=\"text-align: right;\">               0.1</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        12.8294 </td><td style=\"text-align: right;\">          0.103169 </td><td style=\"text-align: right;\">    0.983342</td><td style=\"text-align: right;\">      0.103305 </td></tr>\n",
       "<tr><td>model_creator_7742e1ea</td><td>TERMINATED</td><td>192.168.1.103:641971</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.000884811</td><td>&lt;class &#x27;segment_f240</td><td>mobilenet_v2        </td><td style=\"text-align: right;\">               0.1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.64262</td><td style=\"text-align: right;\">          0.0738334</td><td style=\"text-align: right;\">    0.999216</td><td style=\"text-align: right;\">      0.0738349</td></tr>\n",
       "<tr><td>model_creator_b23d6090</td><td>TERMINATED</td><td>192.168.1.103:644942</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.000334998</td><td>&lt;class &#x27;segment_f240</td><td>timm-efficientnet-b8</td><td style=\"text-align: right;\">               0.3</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        12.9775 </td><td style=\"text-align: right;\">          0.0738971</td><td style=\"text-align: right;\">    0.999956</td><td style=\"text-align: right;\">      0.0738972</td></tr>\n",
       "<tr><td>model_creator_34bb705e</td><td>TERMINATED</td><td>192.168.1.103:645647</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">         352</td><td style=\"text-align: right;\">0.000101363</td><td>&lt;class &#x27;segment_b2d0</td><td>timm-mobilenetv_0a80</td><td style=\"text-align: right;\">               0.3</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        11.2311 </td><td style=\"text-align: right;\">          0.277246 </td><td style=\"text-align: right;\">    0.36927 </td><td style=\"text-align: right;\">      0.526631 </td></tr>\n",
       "<tr><td>model_creator_1614ecc4</td><td>ERROR     </td><td>192.168.1.103:641971</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">         352</td><td style=\"text-align: right;\">0.000332456</td><td>&lt;class &#x27;segment_5c80</td><td>timm-efficientnet-b8</td><td style=\"text-align: right;\">               0.1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                   </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>model_creator_303487b8</td><td>ERROR     </td><td>192.168.1.103:644942</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.000244315</td><td>&lt;class &#x27;segment_b2d0</td><td>timm-efficientnet-b8</td><td style=\"text-align: right;\">               0.5</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">                   </td><td style=\"text-align: right;\">            </td><td style=\"text-align: right;\">               </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tekboart/.local/lib/python3.11/site-packages/optuna/distributions.py:781: FutureWarning: LogUniformDistribution(high=0.001, low=0.0001) is deprecated and internally converted to FloatDistribution(high=0.001, log=True, low=0.0001, step=None). See https://github.com/optuna/optuna/issues/2941.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=641971)\u001b[0m 2023-07-14 11:54:35.815901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Epoch 1:  40%|████      | 2/5 [00:00<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 1/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 5/5 [00:00<00:00, 26.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                0.795886  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.12      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.69      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.07      \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>date               </th><th>done  </th><th>hostname   </th><th>iterations_since_restore  </th><th>node_ip      </th><th style=\"text-align: right;\">   pid</th><th>time_since_restore  </th><th>time_this_iter_s  </th><th>time_total_s      </th><th style=\"text-align: right;\">  timestamp</th><th>training_iteration  </th><th>trial_id  </th><th>val_dice (F1-Score)  </th><th>val_jaccard (IOU)  </th><th>val_loss           </th><th>val_precision      </th><th>val_recall         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>model_creator_1614ecc4</td><td>2023-07-14_11-54-50</td><td>      </td><td>manjaro-dev</td><td>                          </td><td>192.168.1.103</td><td style=\"text-align: right;\">641971</td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689323090</td><td>                    </td><td>1614ecc4  </td><td>                     </td><td>                   </td><td>                   </td><td>                   </td><td>                   </td></tr>\n",
       "<tr><td>model_creator_186d809e</td><td>2023-07-14_11-54-49</td><td>True  </td><td>manjaro-dev</td><td>10                        </td><td>192.168.1.103</td><td style=\"text-align: right;\">641971</td><td>12.829359531402588  </td><td>1.230342149734497 </td><td>12.829359531402588</td><td style=\"text-align: right;\"> 1689323089</td><td>10                  </td><td>186d809e  </td><td>0.1811168616016706   </td><td>0.10316866512099902</td><td>1.2298118472099304 </td><td>0.10330452149113019</td><td>0.9833421508471171 </td></tr>\n",
       "<tr><td>model_creator_303487b8</td><td>2023-07-14_11-55-14</td><td>      </td><td>manjaro-dev</td><td>                          </td><td>192.168.1.103</td><td style=\"text-align: right;\">644942</td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689323114</td><td>                    </td><td>303487b8  </td><td>                     </td><td>                   </td><td>                   </td><td>                   </td><td>                   </td></tr>\n",
       "<tr><td>model_creator_34bb705e</td><td>2023-07-14_11-55-33</td><td>True  </td><td>manjaro-dev</td><td>10                        </td><td>192.168.1.103</td><td style=\"text-align: right;\">645647</td><td>11.23106050491333   </td><td>1.0824763774871826</td><td>11.23106050491333 </td><td style=\"text-align: right;\"> 1689323133</td><td>10                  </td><td>34bb705e  </td><td>0.43413046002388     </td><td>0.2772456109523773 </td><td>0.14304067194461823</td><td>0.5266313552856445 </td><td>0.36926957964897156</td></tr>\n",
       "<tr><td>model_creator_7742e1ea</td><td>2023-07-14_11-54-50</td><td>True  </td><td>manjaro-dev</td><td>1                         </td><td>192.168.1.103</td><td style=\"text-align: right;\">641971</td><td>1.642615556716919   </td><td>1.642615556716919 </td><td>1.642615556716919 </td><td style=\"text-align: right;\"> 1689323090</td><td>1                   </td><td>7742e1ea  </td><td>0.13605224341154099  </td><td>0.07383341528475285</td><td>29.7331485748291   </td><td>0.07383491843938828</td><td>0.9992161691188812 </td></tr>\n",
       "<tr><td>model_creator_b23d6090</td><td>2023-07-14_11-55-14</td><td>True  </td><td>manjaro-dev</td><td>2                         </td><td>192.168.1.103</td><td style=\"text-align: right;\">644942</td><td>12.977480173110962  </td><td>5.5364062786102295</td><td>12.977480173110962</td><td style=\"text-align: right;\"> 1689323114</td><td>2                   </td><td>b23d6090  </td><td>0.1361655853688717   </td><td>0.0738970972597599 </td><td>4.14430034160614   </td><td>0.07389718107879162</td><td>0.9999564588069916 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Epoch 2:  60%|██████    | 3/5 [00:00<00:00, 24.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            2.232531  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.13      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          0.92      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 2/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 5/5 [00:00<00:00, 26.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                0.642723  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.20      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.11      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.89      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.11      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Epoch 3:  60%|██████    | 3/5 [00:00<00:00, 23.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            2.548792  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.14      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          0.99      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 3/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 27.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                0.520741  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.33      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.21      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.92      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.21      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Epoch 4:  60%|██████    | 3/5 [00:00<00:00, 24.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            3.716569  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.13      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          1.00      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 4/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 27.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                0.417163  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.55      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.43      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.94      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.41      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            3.837365  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.13      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          0.99      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m >>> lr_rate was decayed to: 0.000070\n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 5/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 5/5 [00:00<00:00, 26.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                0.379964  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.59      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.50      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.90      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.44      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            2.539305  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.14      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.08      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          0.99      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.08      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 6/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 5/5 [00:00<00:00, 28.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                0.378052  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.57      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.47      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.91      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.42      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Epoch 7:  60%|██████    | 3/5 [00:00<00:00, 25.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            2.301511  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.14      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.08      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          0.99      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.08      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 7/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 5/5 [00:00<00:00, 28.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                0.355753  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.68      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.57      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.94      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.55      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Epoch 8:  60%|██████    | 3/5 [00:00<00:00, 22.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            1.867247  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.15      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.08      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          0.99      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.08      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 8/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 5/5 [00:00<00:00, 27.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                0.358053  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.63      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.55      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.90      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.51      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Epoch 9:  40%|████      | 2/5 [00:00<00:00, 18.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            1.979770  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.14      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.08      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          0.99      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.08      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 9/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 27.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                0.344987  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.66      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.57      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.90      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.53      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Epoch 10:  20%|██        | 1/5 [00:00<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            1.458895  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.16      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.09      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          0.99      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.09      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m --------------------------------- epoch 10/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 5/5 [00:00<00:00, 25.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                0.337612  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.73      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.63      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.93      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.59      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:54:49,134\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'pretrained_arch': ('__ref_ph', 'c70cbae7')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            1.229812  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.18      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.10      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          0.98      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.10      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 1/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3/3 [00:00<00:00, 15.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m loss:                1.141170  \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m dice (F1-Score):     0.09      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m precision:           0.05      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m recall:              0.93      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m jaccard (IOU):       0.05      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:54:50,791\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'pretrained_arch': ('__ref_ph', 'c70cbae7')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_loss:            29.733149 \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_dice (F1-Score): 0.14      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_precision:       0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_recall:          1.00      \n",
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m val_jaccard (IOU):   0.07      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Epoch 1:  33%|███▎      | 1/3 [00:00<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=641971)\u001b[0m ---------------------------------- epoch 1/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3/3 [00:00<00:00, 15.12it/s]\n",
      "2023-07-14 11:54:55,422\tERROR tune_controller.py:873 -- Trial task failed for trial model_creator_1614ecc4\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=641971, ip=192.168.1.103, actor_id=29ce686dde81601c65ce833c01000000, repr=model_creator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n",
      "    return self._trainable_func(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_626211/2825254935.py\", line 160, in model_creator\n",
      "  File \"/run/media/tekboart/SP 2TB/CE - CS/Development/Academic/CHB/2. Semantic Segmentation - damage detection/utils/training.py\", line 396, in fit_fn\n",
      "    train_metrics = train_fn(\n",
      "                    ^^^^^^^^^\n",
      "  File \"/run/media/tekboart/SP 2TB/CE - CS/Development/Academic/CHB/2. Semantic Segmentation - damage detection/utils/training.py\", line 126, in train_fn\n",
      "    yhat = model(x)\n",
      "           ^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/segmentation_models_pytorch/base/model.py\", line 29, in forward\n",
      "    features = self.encoder(x)\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/segmentation_models_pytorch/encoders/timm_efficientnet.py\", line 120, in forward\n",
      "    x = stages[i](x)\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/timm/models/_efficientnet_blocks.py\", line 180, in forward\n",
      "    x = self.conv_pw(x)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 7.92 GiB total capacity; 6.50 GiB already allocated; 109.81 MiB free; 6.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[2m\u001b[36m(pid=644942)\u001b[0m 2023-07-14 11:55:00.915672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Epoch 1:  33%|███▎      | 1/3 [00:00<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m ---------------------------------- epoch 1/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3/3 [00:00<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m loss:                0.815731  \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m dice (F1-Score):     0.10      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m precision:           0.06      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m recall:              0.72      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m jaccard (IOU):       0.06      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m val_loss:            7.508049  \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m val_dice (F1-Score): 0.14      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m val_precision:       0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m val_recall:          1.00      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m val_jaccard (IOU):   0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m ---------------------------------- epoch 2/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Epoch 2:  33%|███▎      | 1/3 [00:00<00:00,  6.74it/s]\n",
      "Epoch 2: 100%|██████████| 3/3 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m loss:                0.684503  \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m dice (F1-Score):     0.17      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m precision:           0.09      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m recall:              0.94      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m jaccard (IOU):       0.09      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:55:14,396\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'pretrained_arch': ('__ref_ph', 'c70cbae7')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m val_loss:            4.144300  \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m val_dice (F1-Score): 0.14      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m val_precision:       0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m val_recall:          1.00      \n",
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m val_jaccard (IOU):   0.07      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=644942)\u001b[0m ---------------------------------- epoch 1/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2/2 [00:00<00:00,  8.40it/s]\n",
      "2023-07-14 11:55:16,618\tERROR tune_controller.py:873 -- Trial task failed for trial model_creator_303487b8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 18, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/_private/worker.py\", line 2540, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=644942, ip=192.168.1.103, actor_id=6ea7b58ca010d701412faec501000000, repr=model_creator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 389, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n",
      "    return self._trainable_func(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/tmp/ipykernel_626211/2825254935.py\", line 160, in model_creator\n",
      "  File \"/run/media/tekboart/SP 2TB/CE - CS/Development/Academic/CHB/2. Semantic Segmentation - damage detection/utils/training.py\", line 396, in fit_fn\n",
      "    train_metrics = train_fn(\n",
      "                    ^^^^^^^^^\n",
      "  File \"/run/media/tekboart/SP 2TB/CE - CS/Development/Academic/CHB/2. Semantic Segmentation - damage detection/utils/training.py\", line 126, in train_fn\n",
      "    yhat = model(x)\n",
      "           ^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/segmentation_models_pytorch/base/model.py\", line 29, in forward\n",
      "    features = self.encoder(x)\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/segmentation_models_pytorch/encoders/timm_efficientnet.py\", line 120, in forward\n",
      "    x = stages[i](x)\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/timm/models/_efficientnet_blocks.py\", line 183, in forward\n",
      "    x = self.bn2(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/timm/layers/norm_act.py\", line 130, in forward\n",
      "    x = self.act(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/timm/layers/activations.py\", line 26, in forward\n",
      "    return swish(x, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tekboart/.local/lib/python3.11/site-packages/timm/layers/activations.py\", line 17, in swish\n",
      "    return x.mul_(x.sigmoid()) if inplace else x.mul(x.sigmoid())\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 7.92 GiB total capacity; 6.33 GiB already allocated; 102.38 MiB free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[2m\u001b[36m(pid=645647)\u001b[0m 2023-07-14 11:55:21.847837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m ---------------------------------- epoch 1/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2/2 [00:00<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m loss:                2.553252  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m dice (F1-Score):     0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m precision:           0.04      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m recall:              0.94      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m jaccard (IOU):       0.04      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Epoch 2:  50%|█████     | 1/2 [00:00<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_loss:            1.330276  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_dice (F1-Score): 0.12      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_precision:       0.06      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_recall:          0.85      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_jaccard (IOU):   0.06      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m ---------------------------------- epoch 2/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2/2 [00:00<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m loss:                2.458742  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m dice (F1-Score):     0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m precision:           0.04      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m recall:              0.87      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m jaccard (IOU):       0.04      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_loss:            0.481332  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_dice (F1-Score): 0.18      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_precision:       0.11      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_recall:          0.43      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_jaccard (IOU):   0.10      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m ---------------------------------- epoch 3/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2/2 [00:00<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m loss:                0.732139  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m dice (F1-Score):     0.08      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m precision:           0.04      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m recall:              0.40      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m jaccard (IOU):       0.04      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_loss:            0.256219  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_dice (F1-Score): 0.09      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_precision:       0.14      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_recall:          0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_jaccard (IOU):   0.05      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m ---------------------------------- epoch 4/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2/2 [00:00<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m loss:                0.471068  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m dice (F1-Score):     0.10      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m precision:           0.11      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m recall:              0.14      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m jaccard (IOU):       0.06      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_loss:            0.223094  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_dice (F1-Score): 0.04      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_precision:       0.19      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_recall:          0.02      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_jaccard (IOU):   0.02      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m ---------------------------------- epoch 5/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2/2 [00:00<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m loss:                0.185487  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m dice (F1-Score):     0.19      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m precision:           0.23      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m recall:              0.17      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m jaccard (IOU):       0.11      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Epoch 6:  50%|█████     | 1/2 [00:00<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_loss:            0.219459  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_dice (F1-Score): 0.03      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_precision:       0.19      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_recall:          0.02      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_jaccard (IOU):   0.02      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m ---------------------------------- epoch 6/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2/2 [00:00<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m loss:                0.142049  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m dice (F1-Score):     0.23      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m precision:           0.48      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m recall:              0.18      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m jaccard (IOU):       0.14      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_loss:            0.206738  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_dice (F1-Score): 0.05      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_precision:       0.21      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_recall:          0.03      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_jaccard (IOU):   0.02      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m ---------------------------------- epoch 7/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2/2 [00:00<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m loss:                0.149899  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m dice (F1-Score):     0.20      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m precision:           0.59      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m recall:              0.12      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m jaccard (IOU):       0.11      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_loss:            0.185922  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_dice (F1-Score): 0.11      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_precision:       0.29      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_recall:          0.07      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_jaccard (IOU):   0.06      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m ---------------------------------- epoch 8/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|█████     | 1/2 [00:00<00:00,  4.83it/s]\n",
      "Epoch 8: 100%|██████████| 2/2 [00:00<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m loss:                0.101207  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m dice (F1-Score):     0.49      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m precision:           0.78      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m recall:              0.37      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m jaccard (IOU):       0.33      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Epoch 9:  50%|█████     | 1/2 [00:00<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_loss:            0.170239  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_dice (F1-Score): 0.19      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_precision:       0.37      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_recall:          0.13      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_jaccard (IOU):   0.10      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m ---------------------------------- epoch 9/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2/2 [00:00<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m loss:                0.089101  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m dice (F1-Score):     0.69      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m precision:           0.78      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m recall:              0.62      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m jaccard (IOU):       0.54      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_loss:            0.157735  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_dice (F1-Score): 0.28      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_precision:       0.44      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_recall:          0.20      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_jaccard (IOU):   0.16      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m --------------------------------- epoch 10/10 ---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 2/2 [00:00<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m loss:                0.070277  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m dice (F1-Score):     0.66      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m precision:           0.68      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m recall:              0.67      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m jaccard (IOU):       0.49      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 11:55:33,561\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'pretrained_arch': ('__ref_ph', 'd08b895f')}\n",
      "2023-07-14 11:55:33,571\tERROR tune.py:1107 -- Trials did not complete: [model_creator_1614ecc4, model_creator_303487b8]\n",
      "2023-07-14 11:55:33,571\tINFO tune.py:1111 -- Total run time: 63.75 seconds (63.70 seconds for the tuning loop).\n",
      "2023-07-14 11:55:33,584\tWARNING experiment_analysis.py:910 -- Failed to read the results for 2 trials:\n",
      "- /home/tekboart/ray_results/model_creator_2023-07-14_11-54-26/model_creator_1614ecc4_3_batch_size=4,image_size=352,lr=0.0003,pretrained_arch=ref_ph_c9fd45ce,pretrained_encoder=timm-efficientne_2023-07-14_11-54-49\n",
      "- /home/tekboart/ray_results/model_creator_2023-07-14_11-54-26/model_creator_303487b8_5_batch_size=8,image_size=256,lr=0.0002,pretrained_arch=ref_ph_d08b895f,pretrained_encoder=timm-efficientne_2023-07-14_11-55-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_loss:            0.143041  \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_dice (F1-Score): 0.43      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_precision:       0.53      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_recall:          0.37      \n",
      "\u001b[2m\u001b[36m(model_creator pid=645647)\u001b[0m val_jaccard (IOU):   0.28      \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_timestamp = datetime.today().strftime(time_format)\n",
    "    # FIXME: chane num_samples=20 and max_num_epochs=10 for Colab Pro\n",
    "    results = hyperparam_tuner(\n",
    "        config=config,\n",
    "        num_samples=60,  #FIXME: Change this to 60\n",
    "        max_num_epochs=10,\n",
    "        # tune_metric=\"val_dice (F1-Score)\",\n",
    "        # tune_metric_mode=\"max\",\n",
    "        tune_metric=\"val_loss\",\n",
    "        tune_metric_mode=\"min\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report the best found hyperparams\n",
    "> You can find the important reports of ... in:\n",
    "* ~/ray_results\n",
    "\n",
    "> Just make sure to delete them if don't need them anymore\n",
    "\n",
    "> The files include:\n",
    "1. The result.json (of the best model)\n",
    "1. The saved checkpoint (of the best model)\n",
    "1. The parameters (of the best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'lr': 0.00010136333446857242, 'scheduler_factor': 0.3, 'batch_size': 8, 'image_size': 352, 'pretrained_arch': <class 'segmentation_models_pytorch.decoders.fpn.model.FPN'>, 'pretrained_encoder': 'timm-mobilenetv3_large_100'}\n",
      "Best trial final val_loss: 0.14304067194461823\n",
      "Best trial final val_jaccard (IOU): 0.2772456109523773\n",
      "Best trial final val_dice (F1-Score): 0.43413046002388\n",
      "Best trial final val_recall: 0.36926957964897156\n",
      "Best trial final val_precision: 0.5266313552856445\n"
     ]
    }
   ],
   "source": [
    "# Get the configs for the best performing model\n",
    "best_trial = results.get_best_result(\"val_loss\", 'min', \"last\")\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "\n",
    "# Define the used metrics\n",
    "metrics = [\"loss\", \"jaccard (IOU)\", \"dice (F1-Score)\", \"recall\", \"precision\"]\n",
    "# add \"val_\" at the beginning\n",
    "metrics_val = [f'val_{metric}' for metric in metrics]\n",
    "\n",
    "for metric in metrics_val:\n",
    "    print(f\"Best trial final {metric}: {best_trial.metrics[metric]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Metrics During Training                            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>val_jaccard (IOU)</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_dice (F1-Score)</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>...</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>config/batch_size</th>\n",
       "      <th>config/image_size</th>\n",
       "      <th>config/lr</th>\n",
       "      <th>config/pretrained_arch</th>\n",
       "      <th>config/pretrained_encoder</th>\n",
       "      <th>config/scheduler_factor</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.103169</td>\n",
       "      <td>0.983342</td>\n",
       "      <td>0.103305</td>\n",
       "      <td>0.181117</td>\n",
       "      <td>1.229812</td>\n",
       "      <td>1.230342</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>186d809e</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.103</td>\n",
       "      <td>12.829360</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>352</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>&lt;class 'segmentation_models_pytorch.decoders.u...</td>\n",
       "      <td>timm-mobilenetv3_large_100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>/home/tekboart/ray_results/model_creator_2023-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.073833</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.073835</td>\n",
       "      <td>0.136052</td>\n",
       "      <td>29.733149</td>\n",
       "      <td>1.642616</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>7742e1ea</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.103</td>\n",
       "      <td>1.642616</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>&lt;class 'segmentation_models_pytorch.decoders.u...</td>\n",
       "      <td>mobilenet_v2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>/home/tekboart/ray_results/model_creator_2023-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.073897</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.073897</td>\n",
       "      <td>0.136166</td>\n",
       "      <td>4.144300</td>\n",
       "      <td>5.536406</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>b23d6090</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.103</td>\n",
       "      <td>12.977480</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>&lt;class 'segmentation_models_pytorch.decoders.u...</td>\n",
       "      <td>timm-efficientnet-b8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>/home/tekboart/ray_results/model_creator_2023-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.277246</td>\n",
       "      <td>0.369270</td>\n",
       "      <td>0.526631</td>\n",
       "      <td>0.434130</td>\n",
       "      <td>0.143041</td>\n",
       "      <td>1.082476</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>34bb705e</td>\n",
       "      <td>...</td>\n",
       "      <td>192.168.1.103</td>\n",
       "      <td>11.231061</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>352</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>&lt;class 'segmentation_models_pytorch.decoders.f...</td>\n",
       "      <td>timm-mobilenetv3_large_100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>/home/tekboart/ray_results/model_creator_2023-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  val_jaccard (IOU)  val_recall  val_precision  val_dice (F1-Score)  \\\n",
       "0      1           0.103169    0.983342       0.103305             0.181117   \n",
       "1      2           0.073833    0.999216       0.073835             0.136052   \n",
       "2      3           0.073897    0.999956       0.073897             0.136166   \n",
       "3      4           0.277246    0.369270       0.526631             0.434130   \n",
       "\n",
       "    val_loss  time_this_iter_s  done  training_iteration  trial_id  ...  \\\n",
       "0   1.229812          1.230342  True                  10  186d809e  ...   \n",
       "1  29.733149          1.642616  True                   1  7742e1ea  ...   \n",
       "2   4.144300          5.536406  True                   2  b23d6090  ...   \n",
       "3   0.143041          1.082476  True                  10  34bb705e  ...   \n",
       "\n",
       "         node_ip  time_since_restore  iterations_since_restore  \\\n",
       "0  192.168.1.103           12.829360                        10   \n",
       "1  192.168.1.103            1.642616                         1   \n",
       "2  192.168.1.103           12.977480                         2   \n",
       "3  192.168.1.103           11.231061                        10   \n",
       "\n",
       "   config/batch_size config/image_size config/lr  \\\n",
       "0                  2               352  0.000701   \n",
       "1                  4               256  0.000885   \n",
       "2                  4               256  0.000335   \n",
       "3                  8               352  0.000101   \n",
       "\n",
       "                              config/pretrained_arch  \\\n",
       "0  <class 'segmentation_models_pytorch.decoders.u...   \n",
       "1  <class 'segmentation_models_pytorch.decoders.u...   \n",
       "2  <class 'segmentation_models_pytorch.decoders.u...   \n",
       "3  <class 'segmentation_models_pytorch.decoders.f...   \n",
       "\n",
       "    config/pretrained_encoder  config/scheduler_factor  \\\n",
       "0  timm-mobilenetv3_large_100                      0.1   \n",
       "1                mobilenet_v2                      0.1   \n",
       "2        timm-efficientnet-b8                      0.3   \n",
       "3  timm-mobilenetv3_large_100                      0.3   \n",
       "\n",
       "                                              logdir  \n",
       "0  /home/tekboart/ray_results/model_creator_2023-...  \n",
       "1  /home/tekboart/ray_results/model_creator_2023-...  \n",
       "2  /home/tekboart/ray_results/model_creator_2023-...  \n",
       "3  /home/tekboart/ray_results/model_creator_2023-...  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print the results as a DataFrame\n",
    "df_results = results.get_dataframe()\n",
    "df_results.insert(loc=0, column=\"Model\", value=range(1, len(df_results.index) + 1))\n",
    "df_results.to_csv(f\"outputs//{train_timestamp}@history_training_train_val.csv\", index=False)\n",
    "print(\" Metrics During Training \".center(79, \" \"))\n",
    "display(df_results)\n",
    "# del df_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Metrics (for all of the trained models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a trial dataframe from all run trials of this `tune.run` call.\n",
    "# dfs = {result: results.get_dataframe()[result] for result in results.get_dataframe()}\n",
    "\n",
    "# plt.plot(dfs['val_loss'])\n",
    "\n",
    "# Plot by epoch\n",
    "# ax = None  # This plots everything on the same plot\n",
    "# for d in dfs.values():\n",
    "    # ax = d['val_loss'].plot(ax=ax, legend=False)\n",
    "    # plt.plot(d['val_loss'])\n",
    "# ax.set_xlabel('Epochs')\n",
    "# ax.set_ylabel(\"val_loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the results\n",
    "> Results are the config and metrics of all the trained models (not just the best one)\n",
    "\n",
    "> We can use results later on to report different performance in table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save hyperparams as a JSON file\n",
    "#TODO: Check the type of results\n",
    "hyper_params_export_name = (\n",
    "    f\"outputs{os.sep}hyperparams_search{os.sep}{train_timestamp}@ray_tuner_hyperparams.json\"\n",
    ")\n",
    "with open(hyper_params_export_name, \"w\") as f:\n",
    "    json.dump(dict(map(lambda x: (x[0], str(x[1])), results)), f)\n",
    "\n",
    "# save the hyperparams to a csv file\n",
    "# df_hyperparam = pd.DataFrame(hyper_params, index=[0]).T\n",
    "# df_hyperparam.to_csv(f'outputs/hyperparams/{start_train_time}@hyperparams.csv', index=True, header=None)\n",
    "# print('The HyperParameters'.ljust(79, \" \"))\n",
    "# display(df_hyperparam)\n",
    "# del df_hyperparam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

digraph {
	graph [size="171.75,171.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140438221995728 [label="
 (1, 1, 224, 224)" fillcolor=darkolivegreen1]
	140438334568960 [label=ConvolutionBackward0]
	140438334570448 -> 140438334568960
	140438334570448 [label=ReluBackward0]
	140438334561472 -> 140438334570448
	140438334561472 [label=NativeBatchNormBackward0]
	140438334568480 -> 140438334561472
	140438334568480 [label=ConvolutionBackward0]
	140438334563440 -> 140438334568480
	140438334563440 [label=ReluBackward0]
	140438334566272 -> 140438334563440
	140438334566272 [label=NativeBatchNormBackward0]
	140438334568240 -> 140438334566272
	140438334568240 [label=ConvolutionBackward0]
	140438334566944 -> 140438334568240
	140438334566944 [label=UpsampleNearest2DBackward0]
	140438334561136 -> 140438334566944
	140438334561136 [label=ReluBackward0]
	140438334562288 -> 140438334561136
	140438334562288 [label=NativeBatchNormBackward0]
	140438334560704 -> 140438334562288
	140438334560704 [label=ConvolutionBackward0]
	140438334560752 -> 140438334560704
	140438334560752 [label=ReluBackward0]
	140438334566752 -> 140438334560752
	140438334566752 [label=NativeBatchNormBackward0]
	140438334562672 -> 140438334566752
	140438334562672 [label=ConvolutionBackward0]
	140438334567952 -> 140438334562672
	140438334567952 [label=CatBackward0]
	140438334567136 -> 140438334567952
	140438334567136 [label=UpsampleNearest2DBackward0]
	140438334568336 -> 140438334567136
	140438334568336 [label=ReluBackward0]
	140438334562240 -> 140438334568336
	140438334562240 [label=NativeBatchNormBackward0]
	140438334559984 -> 140438334562240
	140438334559984 [label=ConvolutionBackward0]
	140438334562480 -> 140438334559984
	140438334562480 [label=ReluBackward0]
	140438334562960 -> 140438334562480
	140438334562960 [label=NativeBatchNormBackward0]
	140438334563056 -> 140438334562960
	140438334563056 [label=ConvolutionBackward0]
	140438334561856 -> 140438334563056
	140438334561856 [label=CatBackward0]
	140438334562000 -> 140438334561856
	140438334562000 [label=UpsampleNearest2DBackward0]
	140438334561760 -> 140438334562000
	140438334561760 [label=ReluBackward0]
	140438334562096 -> 140438334561760
	140438334562096 [label=NativeBatchNormBackward0]
	140438334563104 -> 140438334562096
	140438334563104 [label=ConvolutionBackward0]
	140438334563488 -> 140438334563104
	140438334563488 [label=ReluBackward0]
	140438334563728 -> 140438334563488
	140438334563728 [label=NativeBatchNormBackward0]
	140438334563536 -> 140438334563728
	140438334563536 [label=ConvolutionBackward0]
	140438334563920 -> 140438334563536
	140438334563920 [label=CatBackward0]
	140438334564160 -> 140438334563920
	140438334564160 [label=UpsampleNearest2DBackward0]
	140438334564016 -> 140438334564160
	140438334564016 [label=ReluBackward0]
	140438334564256 -> 140438334564016
	140438334564256 [label=NativeBatchNormBackward0]
	140438334564544 -> 140438334564256
	140438334564544 [label=ConvolutionBackward0]
	140438334564448 -> 140438334564544
	140438334564448 [label=ReluBackward0]
	140438334564736 -> 140438334564448
	140438334564736 [label=NativeBatchNormBackward0]
	140438334564832 -> 140438334564736
	140438334564832 [label=ConvolutionBackward0]
	140438334565984 -> 140438334564832
	140438334565984 [label=CatBackward0]
	140438334565840 -> 140438334565984
	140438334565840 [label=UpsampleNearest2DBackward0]
	140438334567520 -> 140438334565840
	140438334567520 [label=HardtanhBackward0]
	140438334567616 -> 140438334567520
	140438334567616 [label=NativeBatchNormBackward0]
	140438334567712 -> 140438334567616
	140438334567712 [label=ConvolutionBackward0]
	140438334569440 -> 140438334567712
	140438334569440 [label=NativeBatchNormBackward0]
	140438334569584 -> 140438334569440
	140438334569584 [label=ConvolutionBackward0]
	140438334560560 -> 140438334569584
	140438334560560 [label=HardtanhBackward0]
	140438334565168 -> 140438334560560
	140438334565168 [label=NativeBatchNormBackward0]
	140438334560320 -> 140438334565168
	140438334560320 [label=ConvolutionBackward0]
	140443893997312 -> 140438334560320
	140443893997312 [label=HardtanhBackward0]
	140443893994768 -> 140443893997312
	140443893994768 [label=NativeBatchNormBackward0]
	140443893997168 -> 140443893994768
	140443893997168 [label=ConvolutionBackward0]
	140443893994096 -> 140443893997168
	140443893994096 [label=AddBackward0]
	140443893994720 -> 140443893994096
	140443893994720 [label=AddBackward0]
	140443893989776 -> 140443893994720
	140443893989776 [label=NativeBatchNormBackward0]
	140443825679200 -> 140443893989776
	140443825679200 [label=ConvolutionBackward0]
	140443825682656 -> 140443825679200
	140443825682656 [label=HardtanhBackward0]
	140443825679776 -> 140443825682656
	140443825679776 [label=NativeBatchNormBackward0]
	140443825679296 -> 140443825679776
	140443825679296 [label=ConvolutionBackward0]
	140443825683136 -> 140443825679296
	140443825683136 [label=HardtanhBackward0]
	140443825680496 -> 140443825683136
	140443825680496 [label=NativeBatchNormBackward0]
	140443825678960 -> 140443825680496
	140443825678960 [label=ConvolutionBackward0]
	140438334565888 -> 140443825678960
	140438334565888 [label=AddBackward0]
	140443825683184 -> 140438334565888
	140443825683184 [label=AddBackward0]
	140443825679152 -> 140443825683184
	140443825679152 [label=NativeBatchNormBackward0]
	140443825681696 -> 140443825679152
	140443825681696 [label=ConvolutionBackward0]
	140443825682704 -> 140443825681696
	140443825682704 [label=HardtanhBackward0]
	140443825680544 -> 140443825682704
	140443825680544 [label=NativeBatchNormBackward0]
	140443825679104 -> 140443825680544
	140443825679104 [label=ConvolutionBackward0]
	140440497193120 -> 140443825679104
	140440497193120 [label=HardtanhBackward0]
	140440497193264 -> 140440497193120
	140440497193264 [label=NativeBatchNormBackward0]
	140440497193360 -> 140440497193264
	140440497193360 [label=ConvolutionBackward0]
	140440497193552 -> 140440497193360
	140440497193552 [label=AddBackward0]
	140440497193696 -> 140440497193552
	140440497193696 [label=AddBackward0]
	140440497193840 -> 140440497193696
	140440497193840 [label=AddBackward0]
	140440497193984 -> 140440497193840
	140440497193984 [label=NativeBatchNormBackward0]
	140440497194128 -> 140440497193984
	140440497194128 [label=ConvolutionBackward0]
	140440497194320 -> 140440497194128
	140440497194320 [label=HardtanhBackward0]
	140440497194464 -> 140440497194320
	140440497194464 [label=NativeBatchNormBackward0]
	140440497194560 -> 140440497194464
	140440497194560 [label=ConvolutionBackward0]
	140440497194752 -> 140440497194560
	140440497194752 [label=HardtanhBackward0]
	140440497194896 -> 140440497194752
	140440497194896 [label=NativeBatchNormBackward0]
	140440497194992 -> 140440497194896
	140440497194992 [label=ConvolutionBackward0]
	140438334564112 -> 140440497194992
	140438334564112 [label=AddBackward0]
	140440497195280 -> 140438334564112
	140440497195280 [label=AddBackward0]
	140440497195424 -> 140440497195280
	140440497195424 [label=NativeBatchNormBackward0]
	140440497195568 -> 140440497195424
	140440497195568 [label=ConvolutionBackward0]
	140440497195760 -> 140440497195568
	140440497195760 [label=HardtanhBackward0]
	140440497195904 -> 140440497195760
	140440497195904 [label=NativeBatchNormBackward0]
	140440497196000 -> 140440497195904
	140440497196000 [label=ConvolutionBackward0]
	140440497196192 -> 140440497196000
	140440497196192 [label=HardtanhBackward0]
	140440497196336 -> 140440497196192
	140440497196336 [label=NativeBatchNormBackward0]
	140440497196432 -> 140440497196336
	140440497196432 [label=ConvolutionBackward0]
	140438334561952 -> 140440497196432
	140438334561952 [label=AddBackward0]
	140440497196720 -> 140438334561952
	140440497196720 [label=NativeBatchNormBackward0]
	140440497196864 -> 140440497196720
	140440497196864 [label=ConvolutionBackward0]
	140440497197056 -> 140440497196864
	140440497197056 [label=HardtanhBackward0]
	140440497197200 -> 140440497197056
	140440497197200 [label=NativeBatchNormBackward0]
	140440497197296 -> 140440497197200
	140440497197296 [label=ConvolutionBackward0]
	140440497197488 -> 140440497197296
	140440497197488 [label=HardtanhBackward0]
	140440497197632 -> 140440497197488
	140440497197632 [label=NativeBatchNormBackward0]
	140440497197728 -> 140440497197632
	140440497197728 [label=ConvolutionBackward0]
	140438334567088 -> 140440497197728
	140438334567088 [label=NativeBatchNormBackward0]
	140440497198016 -> 140438334567088
	140440497198016 [label=ConvolutionBackward0]
	140440497198208 -> 140440497198016
	140440497198208 [label=HardtanhBackward0]
	140440497198352 -> 140440497198208
	140440497198352 [label=NativeBatchNormBackward0]
	140440497198448 -> 140440497198352
	140440497198448 [label=ConvolutionBackward0]
	140440497198640 -> 140440497198448
	140440497198640 [label=HardtanhBackward0]
	140440497198784 -> 140440497198640
	140440497198784 [label=NativeBatchNormBackward0]
	140440497198880 -> 140440497198784
	140440497198880 [label=ConvolutionBackward0]
	140440497199072 -> 140440497198880
	140440293108192 [label="encoder.features.0.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	140440293108192 -> 140440497199072
	140440497199072 [label=AccumulateGrad]
	140440497198832 -> 140440497198784
	140438387805872 [label="encoder.features.0.1.weight
 (32)" fillcolor=lightblue]
	140438387805872 -> 140440497198832
	140440497198832 [label=AccumulateGrad]
	140440497198688 -> 140440497198784
	140438334721152 [label="encoder.features.0.1.bias
 (32)" fillcolor=lightblue]
	140438334721152 -> 140440497198688
	140440497198688 [label=AccumulateGrad]
	140440497198592 -> 140440497198448
	140438221300320 [label="encoder.features.1.conv.0.0.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	140438221300320 -> 140440497198592
	140440497198592 [label=AccumulateGrad]
	140440497198400 -> 140440497198352
	140443894076656 [label="encoder.features.1.conv.0.1.weight
 (32)" fillcolor=lightblue]
	140443894076656 -> 140440497198400
	140440497198400 [label=AccumulateGrad]
	140440497198256 -> 140440497198352
	140438221300400 [label="encoder.features.1.conv.0.1.bias
 (32)" fillcolor=lightblue]
	140438221300400 -> 140440497198256
	140440497198256 [label=AccumulateGrad]
	140440497198160 -> 140440497198016
	140438221300880 [label="encoder.features.1.conv.1.weight
 (16, 32, 1, 1)" fillcolor=lightblue]
	140438221300880 -> 140440497198160
	140440497198160 [label=AccumulateGrad]
	140440497197968 -> 140438334567088
	140438221300960 [label="encoder.features.1.conv.2.weight
 (16)" fillcolor=lightblue]
	140438221300960 -> 140440497197968
	140440497197968 [label=AccumulateGrad]
	140440497197824 -> 140438334567088
	140438221301040 [label="encoder.features.1.conv.2.bias
 (16)" fillcolor=lightblue]
	140438221301040 -> 140440497197824
	140440497197824 [label=AccumulateGrad]
	140440497197920 -> 140440497197728
	140438221301520 [label="encoder.features.2.conv.0.0.weight
 (96, 16, 1, 1)" fillcolor=lightblue]
	140438221301520 -> 140440497197920
	140440497197920 [label=AccumulateGrad]
	140440497197680 -> 140440497197632
	140438221301440 [label="encoder.features.2.conv.0.1.weight
 (96)" fillcolor=lightblue]
	140438221301440 -> 140440497197680
	140440497197680 [label=AccumulateGrad]
	140440497197536 -> 140440497197632
	140438221301600 [label="encoder.features.2.conv.0.1.bias
 (96)" fillcolor=lightblue]
	140438221301600 -> 140440497197536
	140440497197536 [label=AccumulateGrad]
	140440497197440 -> 140440497197296
	140438221302160 [label="encoder.features.2.conv.1.0.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	140438221302160 -> 140440497197440
	140440497197440 [label=AccumulateGrad]
	140440497197248 -> 140440497197200
	140438221302080 [label="encoder.features.2.conv.1.1.weight
 (96)" fillcolor=lightblue]
	140438221302080 -> 140440497197248
	140440497197248 [label=AccumulateGrad]
	140440497197104 -> 140440497197200
	140438221302240 [label="encoder.features.2.conv.1.1.bias
 (96)" fillcolor=lightblue]
	140438221302240 -> 140440497197104
	140440497197104 [label=AccumulateGrad]
	140440497197008 -> 140440497196864
	140438221302720 [label="encoder.features.2.conv.2.weight
 (24, 96, 1, 1)" fillcolor=lightblue]
	140438221302720 -> 140440497197008
	140440497197008 [label=AccumulateGrad]
	140440497196816 -> 140440497196720
	140438221302800 [label="encoder.features.2.conv.3.weight
 (24)" fillcolor=lightblue]
	140438221302800 -> 140440497196816
	140440497196816 [label=AccumulateGrad]
	140440497196768 -> 140440497196720
	140438221302880 [label="encoder.features.2.conv.3.bias
 (24)" fillcolor=lightblue]
	140438221302880 -> 140440497196768
	140440497196768 [label=AccumulateGrad]
	140440497196672 -> 140438334561952
	140440497196672 [label=NativeBatchNormBackward0]
	140440497197392 -> 140440497196672
	140440497197392 [label=ConvolutionBackward0]
	140440497197776 -> 140440497197392
	140440497197776 [label=HardtanhBackward0]
	140440497198112 -> 140440497197776
	140440497198112 [label=NativeBatchNormBackward0]
	140440497198496 -> 140440497198112
	140440497198496 [label=ConvolutionBackward0]
	140440497198736 -> 140440497198496
	140440497198736 [label=HardtanhBackward0]
	140440497198976 -> 140440497198736
	140440497198976 [label=NativeBatchNormBackward0]
	140440497199264 -> 140440497198976
	140440497199264 [label=ConvolutionBackward0]
	140440497196720 -> 140440497199264
	140440497199456 -> 140440497199264
	140438221303440 [label="encoder.features.3.conv.0.0.weight
 (144, 24, 1, 1)" fillcolor=lightblue]
	140438221303440 -> 140440497199456
	140440497199456 [label=AccumulateGrad]
	140440497199216 -> 140440497198976
	140438221303360 [label="encoder.features.3.conv.0.1.weight
 (144)" fillcolor=lightblue]
	140438221303360 -> 140440497199216
	140440497199216 [label=AccumulateGrad]
	140440497199168 -> 140440497198976
	140438221303520 [label="encoder.features.3.conv.0.1.bias
 (144)" fillcolor=lightblue]
	140438221303520 -> 140440497199168
	140440497199168 [label=AccumulateGrad]
	140440497198928 -> 140440497198496
	140438221304080 [label="encoder.features.3.conv.1.0.weight
 (144, 1, 3, 3)" fillcolor=lightblue]
	140438221304080 -> 140440497198928
	140440497198928 [label=AccumulateGrad]
	140440497198064 -> 140440497198112
	140438221304000 [label="encoder.features.3.conv.1.1.weight
 (144)" fillcolor=lightblue]
	140438221304000 -> 140440497198064
	140440497198064 [label=AccumulateGrad]
	140440497197584 -> 140440497198112
	140438221304160 [label="encoder.features.3.conv.1.1.bias
 (144)" fillcolor=lightblue]
	140438221304160 -> 140440497197584
	140440497197584 [label=AccumulateGrad]
	140440497197872 -> 140440497197392
	140438221304640 [label="encoder.features.3.conv.2.weight
 (24, 144, 1, 1)" fillcolor=lightblue]
	140438221304640 -> 140440497197872
	140440497197872 [label=AccumulateGrad]
	140440497196960 -> 140440497196672
	140438221304720 [label="encoder.features.3.conv.3.weight
 (24)" fillcolor=lightblue]
	140438221304720 -> 140440497196960
	140440497196960 [label=AccumulateGrad]
	140440497196912 -> 140440497196672
	140438221304800 [label="encoder.features.3.conv.3.bias
 (24)" fillcolor=lightblue]
	140438221304800 -> 140440497196912
	140440497196912 [label=AccumulateGrad]
	140440497196624 -> 140440497196432
	140438221305360 [label="encoder.features.4.conv.0.0.weight
 (144, 24, 1, 1)" fillcolor=lightblue]
	140438221305360 -> 140440497196624
	140440497196624 [label=AccumulateGrad]
	140440497196384 -> 140440497196336
	140438221305280 [label="encoder.features.4.conv.0.1.weight
 (144)" fillcolor=lightblue]
	140438221305280 -> 140440497196384
	140440497196384 [label=AccumulateGrad]
	140440497196240 -> 140440497196336
	140438221305440 [label="encoder.features.4.conv.0.1.bias
 (144)" fillcolor=lightblue]
	140438221305440 -> 140440497196240
	140440497196240 [label=AccumulateGrad]
	140440497196144 -> 140440497196000
	140438221306000 [label="encoder.features.4.conv.1.0.weight
 (144, 1, 3, 3)" fillcolor=lightblue]
	140438221306000 -> 140440497196144
	140440497196144 [label=AccumulateGrad]
	140440497195952 -> 140440497195904
	140438221305920 [label="encoder.features.4.conv.1.1.weight
 (144)" fillcolor=lightblue]
	140438221305920 -> 140440497195952
	140440497195952 [label=AccumulateGrad]
	140440497195808 -> 140440497195904
	140438221306080 [label="encoder.features.4.conv.1.1.bias
 (144)" fillcolor=lightblue]
	140438221306080 -> 140440497195808
	140440497195808 [label=AccumulateGrad]
	140440497195712 -> 140440497195568
	140438221306560 [label="encoder.features.4.conv.2.weight
 (32, 144, 1, 1)" fillcolor=lightblue]
	140438221306560 -> 140440497195712
	140440497195712 [label=AccumulateGrad]
	140440497195520 -> 140440497195424
	140438221306640 [label="encoder.features.4.conv.3.weight
 (32)" fillcolor=lightblue]
	140438221306640 -> 140440497195520
	140440497195520 [label=AccumulateGrad]
	140440497195472 -> 140440497195424
	140438221306720 [label="encoder.features.4.conv.3.bias
 (32)" fillcolor=lightblue]
	140438221306720 -> 140440497195472
	140440497195472 [label=AccumulateGrad]
	140440497195376 -> 140440497195280
	140440497195376 [label=NativeBatchNormBackward0]
	140440497196096 -> 140440497195376
	140440497196096 [label=ConvolutionBackward0]
	140440497196480 -> 140440497196096
	140440497196480 [label=HardtanhBackward0]
	140440497197344 -> 140440497196480
	140440497197344 [label=NativeBatchNormBackward0]
	140440497199024 -> 140440497197344
	140440497199024 [label=ConvolutionBackward0]
	140440497199312 -> 140440497199024
	140440497199312 [label=HardtanhBackward0]
	140440497199504 -> 140440497199312
	140440497199504 [label=NativeBatchNormBackward0]
	140440497199600 -> 140440497199504
	140440497199600 [label=ConvolutionBackward0]
	140440497195424 -> 140440497199600
	140440497199792 -> 140440497199600
	140438221307280 [label="encoder.features.5.conv.0.0.weight
 (192, 32, 1, 1)" fillcolor=lightblue]
	140438221307280 -> 140440497199792
	140440497199792 [label=AccumulateGrad]
	140440497199360 -> 140440497199504
	140438221307200 [label="encoder.features.5.conv.0.1.weight
 (192)" fillcolor=lightblue]
	140438221307200 -> 140440497199360
	140440497199360 [label=AccumulateGrad]
	140440497199120 -> 140440497199504
	140438221307360 [label="encoder.features.5.conv.0.1.bias
 (192)" fillcolor=lightblue]
	140438221307360 -> 140440497199120
	140440497199120 [label=AccumulateGrad]
	140440497199408 -> 140440497199024
	140438221439056 [label="encoder.features.5.conv.1.0.weight
 (192, 1, 3, 3)" fillcolor=lightblue]
	140438221439056 -> 140440497199408
	140440497199408 [label=AccumulateGrad]
	140440497196528 -> 140440497197344
	140438221307840 [label="encoder.features.5.conv.1.1.weight
 (192)" fillcolor=lightblue]
	140438221307840 -> 140440497196528
	140440497196528 [label=AccumulateGrad]
	140440497196288 -> 140440497197344
	140438221439136 [label="encoder.features.5.conv.1.1.bias
 (192)" fillcolor=lightblue]
	140438221439136 -> 140440497196288
	140440497196288 [label=AccumulateGrad]
	140440497196576 -> 140440497196096
	140438221439616 [label="encoder.features.5.conv.2.weight
 (32, 192, 1, 1)" fillcolor=lightblue]
	140438221439616 -> 140440497196576
	140440497196576 [label=AccumulateGrad]
	140440497195664 -> 140440497195376
	140438221439696 [label="encoder.features.5.conv.3.weight
 (32)" fillcolor=lightblue]
	140438221439696 -> 140440497195664
	140440497195664 [label=AccumulateGrad]
	140440497195616 -> 140440497195376
	140438221439776 [label="encoder.features.5.conv.3.bias
 (32)" fillcolor=lightblue]
	140438221439776 -> 140440497195616
	140440497195616 [label=AccumulateGrad]
	140440497195232 -> 140438334564112
	140440497195232 [label=NativeBatchNormBackward0]
	140440497195856 -> 140440497195232
	140440497195856 [label=ConvolutionBackward0]
	140440497199744 -> 140440497195856
	140440497199744 [label=HardtanhBackward0]
	140440497199888 -> 140440497199744
	140440497199888 [label=NativeBatchNormBackward0]
	140440497199696 -> 140440497199888
	140440497199696 [label=ConvolutionBackward0]
	140440497200080 -> 140440497199696
	140440497200080 [label=HardtanhBackward0]
	140440497200224 -> 140440497200080
	140440497200224 [label=NativeBatchNormBackward0]
	140440497200320 -> 140440497200224
	140440497200320 [label=ConvolutionBackward0]
	140440497195280 -> 140440497200320
	140440497200512 -> 140440497200320
	140438221440336 [label="encoder.features.6.conv.0.0.weight
 (192, 32, 1, 1)" fillcolor=lightblue]
	140438221440336 -> 140440497200512
	140440497200512 [label=AccumulateGrad]
	140440497200272 -> 140440497200224
	140438221440256 [label="encoder.features.6.conv.0.1.weight
 (192)" fillcolor=lightblue]
	140438221440256 -> 140440497200272
	140440497200272 [label=AccumulateGrad]
	140440497200128 -> 140440497200224
	140438221440416 [label="encoder.features.6.conv.0.1.bias
 (192)" fillcolor=lightblue]
	140438221440416 -> 140440497200128
	140440497200128 [label=AccumulateGrad]
	140440497200032 -> 140440497199696
	140438221440976 [label="encoder.features.6.conv.1.0.weight
 (192, 1, 3, 3)" fillcolor=lightblue]
	140438221440976 -> 140440497200032
	140440497200032 [label=AccumulateGrad]
	140440497199840 -> 140440497199888
	140438221440896 [label="encoder.features.6.conv.1.1.weight
 (192)" fillcolor=lightblue]
	140438221440896 -> 140440497199840
	140440497199840 [label=AccumulateGrad]
	140440497199648 -> 140440497199888
	140438221441056 [label="encoder.features.6.conv.1.1.bias
 (192)" fillcolor=lightblue]
	140438221441056 -> 140440497199648
	140440497199648 [label=AccumulateGrad]
	140440497197152 -> 140440497195856
	140438221441536 [label="encoder.features.6.conv.2.weight
 (32, 192, 1, 1)" fillcolor=lightblue]
	140438221441536 -> 140440497197152
	140440497197152 [label=AccumulateGrad]
	140440497196048 -> 140440497195232
	140438221441616 [label="encoder.features.6.conv.3.weight
 (32)" fillcolor=lightblue]
	140438221441616 -> 140440497196048
	140440497196048 [label=AccumulateGrad]
	140440497195328 -> 140440497195232
	140438221441696 [label="encoder.features.6.conv.3.bias
 (32)" fillcolor=lightblue]
	140438221441696 -> 140440497195328
	140440497195328 [label=AccumulateGrad]
	140440497195184 -> 140440497194992
	140438221442256 [label="encoder.features.7.conv.0.0.weight
 (192, 32, 1, 1)" fillcolor=lightblue]
	140438221442256 -> 140440497195184
	140440497195184 [label=AccumulateGrad]
	140440497194944 -> 140440497194896
	140438221442176 [label="encoder.features.7.conv.0.1.weight
 (192)" fillcolor=lightblue]
	140438221442176 -> 140440497194944
	140440497194944 [label=AccumulateGrad]
	140440497194800 -> 140440497194896
	140438221442336 [label="encoder.features.7.conv.0.1.bias
 (192)" fillcolor=lightblue]
	140438221442336 -> 140440497194800
	140440497194800 [label=AccumulateGrad]
	140440497194704 -> 140440497194560
	140438221442896 [label="encoder.features.7.conv.1.0.weight
 (192, 1, 3, 3)" fillcolor=lightblue]
	140438221442896 -> 140440497194704
	140440497194704 [label=AccumulateGrad]
	140440497194512 -> 140440497194464
	140438221442816 [label="encoder.features.7.conv.1.1.weight
 (192)" fillcolor=lightblue]
	140438221442816 -> 140440497194512
	140440497194512 [label=AccumulateGrad]
	140440497194368 -> 140440497194464
	140438221442976 [label="encoder.features.7.conv.1.1.bias
 (192)" fillcolor=lightblue]
	140438221442976 -> 140440497194368
	140440497194368 [label=AccumulateGrad]
	140440497194272 -> 140440497194128
	140438221443456 [label="encoder.features.7.conv.2.weight
 (64, 192, 1, 1)" fillcolor=lightblue]
	140438221443456 -> 140440497194272
	140440497194272 [label=AccumulateGrad]
	140440497194080 -> 140440497193984
	140438221443536 [label="encoder.features.7.conv.3.weight
 (64)" fillcolor=lightblue]
	140438221443536 -> 140440497194080
	140440497194080 [label=AccumulateGrad]
	140440497194032 -> 140440497193984
	140438221443616 [label="encoder.features.7.conv.3.bias
 (64)" fillcolor=lightblue]
	140438221443616 -> 140440497194032
	140440497194032 [label=AccumulateGrad]
	140440497193936 -> 140440497193840
	140440497193936 [label=NativeBatchNormBackward0]
	140440497194656 -> 140440497193936
	140440497194656 [label=ConvolutionBackward0]
	140440497195040 -> 140440497194656
	140440497195040 [label=HardtanhBackward0]
	140440497198544 -> 140440497195040
	140440497198544 [label=NativeBatchNormBackward0]
	140440497199984 -> 140440497198544
	140440497199984 [label=ConvolutionBackward0]
	140440497200368 -> 140440497199984
	140440497200368 [label=HardtanhBackward0]
	140440497200560 -> 140440497200368
	140440497200560 [label=NativeBatchNormBackward0]
	140440497200656 -> 140440497200560
	140440497200656 [label=ConvolutionBackward0]
	140440497193984 -> 140440497200656
	140440497200848 -> 140440497200656
	140438221444176 [label="encoder.features.8.conv.0.0.weight
 (384, 64, 1, 1)" fillcolor=lightblue]
	140438221444176 -> 140440497200848
	140440497200848 [label=AccumulateGrad]
	140440497200416 -> 140440497200560
	140438221444096 [label="encoder.features.8.conv.0.1.weight
 (384)" fillcolor=lightblue]
	140438221444096 -> 140440497200416
	140440497200416 [label=AccumulateGrad]
	140440497200176 -> 140440497200560
	140438221444256 [label="encoder.features.8.conv.0.1.bias
 (384)" fillcolor=lightblue]
	140438221444256 -> 140440497200176
	140440497200176 [label=AccumulateGrad]
	140440497200464 -> 140440497199984
	140438221444816 [label="encoder.features.8.conv.1.0.weight
 (384, 1, 3, 3)" fillcolor=lightblue]
	140438221444816 -> 140440497200464
	140440497200464 [label=AccumulateGrad]
	140440497195088 -> 140440497198544
	140438221444736 [label="encoder.features.8.conv.1.1.weight
 (384)" fillcolor=lightblue]
	140438221444736 -> 140440497195088
	140440497195088 [label=AccumulateGrad]
	140440497194848 -> 140440497198544
	140438221444896 [label="encoder.features.8.conv.1.1.bias
 (384)" fillcolor=lightblue]
	140438221444896 -> 140440497194848
	140440497194848 [label=AccumulateGrad]
	140440497195136 -> 140440497194656
	140438221445376 [label="encoder.features.8.conv.2.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140438221445376 -> 140440497195136
	140440497195136 [label=AccumulateGrad]
	140440497194224 -> 140440497193936
	140438221445456 [label="encoder.features.8.conv.3.weight
 (64)" fillcolor=lightblue]
	140438221445456 -> 140440497194224
	140440497194224 [label=AccumulateGrad]
	140440497194176 -> 140440497193936
	140438221445536 [label="encoder.features.8.conv.3.bias
 (64)" fillcolor=lightblue]
	140438221445536 -> 140440497194176
	140440497194176 [label=AccumulateGrad]
	140440497193792 -> 140440497193696
	140440497193792 [label=NativeBatchNormBackward0]
	140440497194416 -> 140440497193792
	140440497194416 [label=ConvolutionBackward0]
	140440497200800 -> 140440497194416
	140440497200800 [label=HardtanhBackward0]
	140440497200944 -> 140440497200800
	140440497200944 [label=NativeBatchNormBackward0]
	140440497200752 -> 140440497200944
	140440497200752 [label=ConvolutionBackward0]
	140440497201136 -> 140440497200752
	140440497201136 [label=HardtanhBackward0]
	140440497201280 -> 140440497201136
	140440497201280 [label=NativeBatchNormBackward0]
	140440497201376 -> 140440497201280
	140440497201376 [label=ConvolutionBackward0]
	140440497193840 -> 140440497201376
	140440497201568 -> 140440497201376
	140438221446096 [label="encoder.features.9.conv.0.0.weight
 (384, 64, 1, 1)" fillcolor=lightblue]
	140438221446096 -> 140440497201568
	140440497201568 [label=AccumulateGrad]
	140440497201328 -> 140440497201280
	140438221446016 [label="encoder.features.9.conv.0.1.weight
 (384)" fillcolor=lightblue]
	140438221446016 -> 140440497201328
	140440497201328 [label=AccumulateGrad]
	140440497201184 -> 140440497201280
	140438221446176 [label="encoder.features.9.conv.0.1.bias
 (384)" fillcolor=lightblue]
	140438221446176 -> 140440497201184
	140440497201184 [label=AccumulateGrad]
	140440497201088 -> 140440497200752
	140438221446656 [label="encoder.features.9.conv.1.0.weight
 (384, 1, 3, 3)" fillcolor=lightblue]
	140438221446656 -> 140440497201088
	140440497201088 [label=AccumulateGrad]
	140440497200896 -> 140440497200944
	140438221446576 [label="encoder.features.9.conv.1.1.weight
 (384)" fillcolor=lightblue]
	140438221446576 -> 140440497200896
	140440497200896 [label=AccumulateGrad]
	140440497200704 -> 140440497200944
	140438221446736 [label="encoder.features.9.conv.1.1.bias
 (384)" fillcolor=lightblue]
	140438221446736 -> 140440497200704
	140440497200704 [label=AccumulateGrad]
	140440497198304 -> 140440497194416
	140438221447216 [label="encoder.features.9.conv.2.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140438221447216 -> 140440497198304
	140440497198304 [label=AccumulateGrad]
	140440497194608 -> 140440497193792
	140438221447296 [label="encoder.features.9.conv.3.weight
 (64)" fillcolor=lightblue]
	140438221447296 -> 140440497194608
	140440497194608 [label=AccumulateGrad]
	140440497193888 -> 140440497193792
	140438221447376 [label="encoder.features.9.conv.3.bias
 (64)" fillcolor=lightblue]
	140438221447376 -> 140440497193888
	140440497193888 [label=AccumulateGrad]
	140440497193648 -> 140440497193552
	140440497193648 [label=NativeBatchNormBackward0]
	140440497199936 -> 140440497193648
	140440497199936 [label=ConvolutionBackward0]
	140440497201520 -> 140440497199936
	140440497201520 [label=HardtanhBackward0]
	140440497201664 -> 140440497201520
	140440497201664 [label=NativeBatchNormBackward0]
	140440497201472 -> 140440497201664
	140440497201472 [label=ConvolutionBackward0]
	140440497201856 -> 140440497201472
	140440497201856 [label=HardtanhBackward0]
	140440497202000 -> 140440497201856
	140440497202000 [label=NativeBatchNormBackward0]
	140440497202096 -> 140440497202000
	140440497202096 [label=ConvolutionBackward0]
	140440497193696 -> 140440497202096
	140440497202288 -> 140440497202096
	140438221447936 [label="encoder.features.10.conv.0.0.weight
 (384, 64, 1, 1)" fillcolor=lightblue]
	140438221447936 -> 140440497202288
	140440497202288 [label=AccumulateGrad]
	140440497202048 -> 140440497202000
	140438221447856 [label="encoder.features.10.conv.0.1.weight
 (384)" fillcolor=lightblue]
	140438221447856 -> 140440497202048
	140440497202048 [label=AccumulateGrad]
	140440497201904 -> 140440497202000
	140438221448016 [label="encoder.features.10.conv.0.1.bias
 (384)" fillcolor=lightblue]
	140438221448016 -> 140440497201904
	140440497201904 [label=AccumulateGrad]
	140440497201808 -> 140440497201472
	140438221448576 [label="encoder.features.10.conv.1.0.weight
 (384, 1, 3, 3)" fillcolor=lightblue]
	140438221448576 -> 140440497201808
	140440497201808 [label=AccumulateGrad]
	140440497201616 -> 140440497201664
	140438221448496 [label="encoder.features.10.conv.1.1.weight
 (384)" fillcolor=lightblue]
	140438221448496 -> 140440497201616
	140440497201616 [label=AccumulateGrad]
	140440497201424 -> 140440497201664
	140438221448656 [label="encoder.features.10.conv.1.1.bias
 (384)" fillcolor=lightblue]
	140438221448656 -> 140440497201424
	140440497201424 [label=AccumulateGrad]
	140440497200608 -> 140440497199936
	140438221449136 [label="encoder.features.10.conv.2.weight
 (64, 384, 1, 1)" fillcolor=lightblue]
	140438221449136 -> 140440497200608
	140440497200608 [label=AccumulateGrad]
	140440497199552 -> 140440497193648
	140438221449216 [label="encoder.features.10.conv.3.weight
 (64)" fillcolor=lightblue]
	140438221449216 -> 140440497199552
	140440497199552 [label=AccumulateGrad]
	140440497193744 -> 140440497193648
	140438221449296 [label="encoder.features.10.conv.3.bias
 (64)" fillcolor=lightblue]
	140438221449296 -> 140440497193744
	140440497193744 [label=AccumulateGrad]
	140440497193504 -> 140440497193360
	140438221449856 [label="encoder.features.11.conv.0.0.weight
 (384, 64, 1, 1)" fillcolor=lightblue]
	140438221449856 -> 140440497193504
	140440497193504 [label=AccumulateGrad]
	140440497193312 -> 140440497193264
	140438221449776 [label="encoder.features.11.conv.0.1.weight
 (384)" fillcolor=lightblue]
	140438221449776 -> 140440497193312
	140440497193312 [label=AccumulateGrad]
	140440497193168 -> 140440497193264
	140438221449936 [label="encoder.features.11.conv.0.1.bias
 (384)" fillcolor=lightblue]
	140438221449936 -> 140440497193168
	140440497193168 [label=AccumulateGrad]
	140440497193072 -> 140443825679104
	140438221450496 [label="encoder.features.11.conv.1.0.weight
 (384, 1, 3, 3)" fillcolor=lightblue]
	140438221450496 -> 140440497193072
	140440497193072 [label=AccumulateGrad]
	140443825680352 -> 140443825680544
	140438221450416 [label="encoder.features.11.conv.1.1.weight
 (384)" fillcolor=lightblue]
	140438221450416 -> 140443825680352
	140443825680352 [label=AccumulateGrad]
	140443825683040 -> 140443825680544
	140438221450576 [label="encoder.features.11.conv.1.1.bias
 (384)" fillcolor=lightblue]
	140438221450576 -> 140443825683040
	140443825683040 [label=AccumulateGrad]
	140443825680784 -> 140443825681696
	140438221451056 [label="encoder.features.11.conv.2.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	140438221451056 -> 140443825680784
	140443825680784 [label=AccumulateGrad]
	140443825683856 -> 140443825679152
	140438221451136 [label="encoder.features.11.conv.3.weight
 (96)" fillcolor=lightblue]
	140438221451136 -> 140443825683856
	140443825683856 [label=AccumulateGrad]
	140443825680160 -> 140443825679152
	140438221451216 [label="encoder.features.11.conv.3.bias
 (96)" fillcolor=lightblue]
	140438221451216 -> 140443825680160
	140443825680160 [label=AccumulateGrad]
	140443825683376 -> 140443825683184
	140443825683376 [label=NativeBatchNormBackward0]
	140443825680976 -> 140443825683376
	140443825680976 [label=ConvolutionBackward0]
	140440497193408 -> 140443825680976
	140440497193408 [label=HardtanhBackward0]
	140440497201040 -> 140440497193408
	140440497201040 [label=NativeBatchNormBackward0]
	140440497201760 -> 140440497201040
	140440497201760 [label=ConvolutionBackward0]
	140440497202144 -> 140440497201760
	140440497202144 [label=HardtanhBackward0]
	140440497202336 -> 140440497202144
	140440497202336 [label=NativeBatchNormBackward0]
	140440497202432 -> 140440497202336
	140440497202432 [label=ConvolutionBackward0]
	140443825679152 -> 140440497202432
	140440497202624 -> 140440497202432
	140438221451776 [label="encoder.features.12.conv.0.0.weight
 (576, 96, 1, 1)" fillcolor=lightblue]
	140438221451776 -> 140440497202624
	140440497202624 [label=AccumulateGrad]
	140440497202192 -> 140440497202336
	140438221451696 [label="encoder.features.12.conv.0.1.weight
 (576)" fillcolor=lightblue]
	140438221451696 -> 140440497202192
	140440497202192 [label=AccumulateGrad]
	140440497201952 -> 140440497202336
	140438221451856 [label="encoder.features.12.conv.0.1.bias
 (576)" fillcolor=lightblue]
	140438221451856 -> 140440497201952
	140440497201952 [label=AccumulateGrad]
	140440497202240 -> 140440497201760
	140438221452416 [label="encoder.features.12.conv.1.0.weight
 (576, 1, 3, 3)" fillcolor=lightblue]
	140438221452416 -> 140440497202240
	140440497202240 [label=AccumulateGrad]
	140440497193600 -> 140440497201040
	140438221452336 [label="encoder.features.12.conv.1.1.weight
 (576)" fillcolor=lightblue]
	140438221452336 -> 140440497193600
	140440497193600 [label=AccumulateGrad]
	140440497193216 -> 140440497201040
	140438221452496 [label="encoder.features.12.conv.1.1.bias
 (576)" fillcolor=lightblue]
	140438221452496 -> 140440497193216
	140440497193216 [label=AccumulateGrad]
	140440497193456 -> 140443825680976
	140438221452976 [label="encoder.features.12.conv.2.weight
 (96, 576, 1, 1)" fillcolor=lightblue]
	140438221452976 -> 140440497193456
	140440497193456 [label=AccumulateGrad]
	140443825683280 -> 140443825683376
	140438221453056 [label="encoder.features.12.conv.3.weight
 (96)" fillcolor=lightblue]
	140438221453056 -> 140443825683280
	140443825683280 [label=AccumulateGrad]
	140443825680256 -> 140443825683376
	140438221453136 [label="encoder.features.12.conv.3.bias
 (96)" fillcolor=lightblue]
	140438221453136 -> 140443825680256
	140443825680256 [label=AccumulateGrad]
	140443825683328 -> 140438334565888
	140443825683328 [label=NativeBatchNormBackward0]
	140443825679056 -> 140443825683328
	140443825679056 [label=ConvolutionBackward0]
	140440497202576 -> 140443825679056
	140440497202576 [label=HardtanhBackward0]
	140440497202720 -> 140440497202576
	140440497202720 [label=NativeBatchNormBackward0]
	140440497202528 -> 140440497202720
	140440497202528 [label=ConvolutionBackward0]
	140440497202912 -> 140440497202528
	140440497202912 [label=HardtanhBackward0]
	140440497203056 -> 140440497202912
	140440497203056 [label=NativeBatchNormBackward0]
	140440497203152 -> 140440497203056
	140440497203152 [label=ConvolutionBackward0]
	140443825683184 -> 140440497203152
	140440497203344 -> 140440497203152
	140438221453696 [label="encoder.features.13.conv.0.0.weight
 (576, 96, 1, 1)" fillcolor=lightblue]
	140438221453696 -> 140440497203344
	140440497203344 [label=AccumulateGrad]
	140440497203104 -> 140440497203056
	140438221453616 [label="encoder.features.13.conv.0.1.weight
 (576)" fillcolor=lightblue]
	140438221453616 -> 140440497203104
	140440497203104 [label=AccumulateGrad]
	140440497202960 -> 140440497203056
	140438221453776 [label="encoder.features.13.conv.0.1.bias
 (576)" fillcolor=lightblue]
	140438221453776 -> 140440497202960
	140440497202960 [label=AccumulateGrad]
	140440497202864 -> 140440497202528
	140438221454336 [label="encoder.features.13.conv.1.0.weight
 (576, 1, 3, 3)" fillcolor=lightblue]
	140438221454336 -> 140440497202864
	140440497202864 [label=AccumulateGrad]
	140440497202672 -> 140440497202720
	140438221454256 [label="encoder.features.13.conv.1.1.weight
 (576)" fillcolor=lightblue]
	140438221454256 -> 140440497202672
	140440497202672 [label=AccumulateGrad]
	140440497202480 -> 140440497202720
	140438221454416 [label="encoder.features.13.conv.1.1.bias
 (576)" fillcolor=lightblue]
	140438221454416 -> 140440497202480
	140440497202480 [label=AccumulateGrad]
	140440497200992 -> 140443825679056
	140438221454896 [label="encoder.features.13.conv.2.weight
 (96, 576, 1, 1)" fillcolor=lightblue]
	140438221454896 -> 140440497200992
	140440497200992 [label=AccumulateGrad]
	140443825683232 -> 140443825683328
	140438221454976 [label="encoder.features.13.conv.3.weight
 (96)" fillcolor=lightblue]
	140438221454976 -> 140443825683232
	140443825683232 [label=AccumulateGrad]
	140440497193024 -> 140443825683328
	140438221455056 [label="encoder.features.13.conv.3.bias
 (96)" fillcolor=lightblue]
	140438221455056 -> 140440497193024
	140440497193024 [label=AccumulateGrad]
	140443825679728 -> 140443825678960
	140438221734208 [label="encoder.features.14.conv.0.0.weight
 (576, 96, 1, 1)" fillcolor=lightblue]
	140438221734208 -> 140443825679728
	140443825679728 [label=AccumulateGrad]
	140443825680592 -> 140443825680496
	140438221734128 [label="encoder.features.14.conv.0.1.weight
 (576)" fillcolor=lightblue]
	140438221734128 -> 140443825680592
	140443825680592 [label=AccumulateGrad]
	140443825679248 -> 140443825680496
	140438221734288 [label="encoder.features.14.conv.0.1.bias
 (576)" fillcolor=lightblue]
	140438221734288 -> 140443825679248
	140443825679248 [label=AccumulateGrad]
	140443825682560 -> 140443825679296
	140438221734848 [label="encoder.features.14.conv.1.0.weight
 (576, 1, 3, 3)" fillcolor=lightblue]
	140438221734848 -> 140443825682560
	140443825682560 [label=AccumulateGrad]
	140443825679008 -> 140443825679776
	140438221734768 [label="encoder.features.14.conv.1.1.weight
 (576)" fillcolor=lightblue]
	140438221734768 -> 140443825679008
	140443825679008 [label=AccumulateGrad]
	140443825682032 -> 140443825679776
	140438221734928 [label="encoder.features.14.conv.1.1.bias
 (576)" fillcolor=lightblue]
	140438221734928 -> 140443825682032
	140443825682032 [label=AccumulateGrad]
	140443825680640 -> 140443825679200
	140438221735408 [label="encoder.features.14.conv.2.weight
 (160, 576, 1, 1)" fillcolor=lightblue]
	140438221735408 -> 140443825680640
	140443825680640 [label=AccumulateGrad]
	140443825680448 -> 140443893989776
	140438221735488 [label="encoder.features.14.conv.3.weight
 (160)" fillcolor=lightblue]
	140438221735488 -> 140443825680448
	140443825680448 [label=AccumulateGrad]
	140443825679440 -> 140443893989776
	140438221735568 [label="encoder.features.14.conv.3.bias
 (160)" fillcolor=lightblue]
	140438221735568 -> 140443825679440
	140443825679440 [label=AccumulateGrad]
	140443825680208 -> 140443893994720
	140443825680208 [label=NativeBatchNormBackward0]
	140443825679392 -> 140443825680208
	140443825679392 [label=ConvolutionBackward0]
	140443825684000 -> 140443825679392
	140443825684000 [label=HardtanhBackward0]
	140443825682800 -> 140443825684000
	140443825682800 [label=NativeBatchNormBackward0]
	140440497202816 -> 140443825682800
	140440497202816 [label=ConvolutionBackward0]
	140440497203200 -> 140440497202816
	140440497203200 [label=HardtanhBackward0]
	140440497203392 -> 140440497203200
	140440497203392 [label=NativeBatchNormBackward0]
	140440497203488 -> 140440497203392
	140440497203488 [label=ConvolutionBackward0]
	140443893989776 -> 140440497203488
	140440497203680 -> 140440497203488
	140438221736128 [label="encoder.features.15.conv.0.0.weight
 (960, 160, 1, 1)" fillcolor=lightblue]
	140438221736128 -> 140440497203680
	140440497203680 [label=AccumulateGrad]
	140440497203248 -> 140440497203392
	140438221736048 [label="encoder.features.15.conv.0.1.weight
 (960)" fillcolor=lightblue]
	140438221736048 -> 140440497203248
	140440497203248 [label=AccumulateGrad]
	140440497203008 -> 140440497203392
	140438221736208 [label="encoder.features.15.conv.0.1.bias
 (960)" fillcolor=lightblue]
	140438221736208 -> 140440497203008
	140440497203008 [label=AccumulateGrad]
	140440497203296 -> 140440497202816
	140438221736768 [label="encoder.features.15.conv.1.0.weight
 (960, 1, 3, 3)" fillcolor=lightblue]
	140438221736768 -> 140440497203296
	140440497203296 [label=AccumulateGrad]
	140440497201232 -> 140443825682800
	140438221736688 [label="encoder.features.15.conv.1.1.weight
 (960)" fillcolor=lightblue]
	140438221736688 -> 140440497201232
	140440497201232 [label=AccumulateGrad]
	140440497201712 -> 140443825682800
	140438221736848 [label="encoder.features.15.conv.1.1.bias
 (960)" fillcolor=lightblue]
	140438221736848 -> 140440497201712
	140440497201712 [label=AccumulateGrad]
	140443825680928 -> 140443825679392
	140438221737248 [label="encoder.features.15.conv.2.weight
 (160, 960, 1, 1)" fillcolor=lightblue]
	140438221737248 -> 140443825680928
	140443825680928 [label=AccumulateGrad]
	140443825680880 -> 140443825680208
	140438221737328 [label="encoder.features.15.conv.3.weight
 (160)" fillcolor=lightblue]
	140438221737328 -> 140443825680880
	140443825680880 [label=AccumulateGrad]
	140443825682608 -> 140443825680208
	140438221737408 [label="encoder.features.15.conv.3.bias
 (160)" fillcolor=lightblue]
	140438221737408 -> 140443825682608
	140443825682608 [label=AccumulateGrad]
	140443893997744 -> 140443893994096
	140443893997744 [label=NativeBatchNormBackward0]
	140443825680304 -> 140443893997744
	140443825680304 [label=ConvolutionBackward0]
	140440497203632 -> 140443825680304
	140440497203632 [label=HardtanhBackward0]
	140440497203776 -> 140440497203632
	140440497203776 [label=NativeBatchNormBackward0]
	140440497203584 -> 140440497203776
	140440497203584 [label=ConvolutionBackward0]
	140440497203968 -> 140440497203584
	140440497203968 [label=HardtanhBackward0]
	140440497204112 -> 140440497203968
	140440497204112 [label=NativeBatchNormBackward0]
	140440497204208 -> 140440497204112
	140440497204208 [label=ConvolutionBackward0]
	140443893994720 -> 140440497204208
	140440497204400 -> 140440497204208
	140438221737968 [label="encoder.features.16.conv.0.0.weight
 (960, 160, 1, 1)" fillcolor=lightblue]
	140438221737968 -> 140440497204400
	140440497204400 [label=AccumulateGrad]
	140440497204160 -> 140440497204112
	140438221737888 [label="encoder.features.16.conv.0.1.weight
 (960)" fillcolor=lightblue]
	140438221737888 -> 140440497204160
	140440497204160 [label=AccumulateGrad]
	140440497204016 -> 140440497204112
	140438221738048 [label="encoder.features.16.conv.0.1.bias
 (960)" fillcolor=lightblue]
	140438221738048 -> 140440497204016
	140440497204016 [label=AccumulateGrad]
	140440497203920 -> 140440497203584
	140438221738608 [label="encoder.features.16.conv.1.0.weight
 (960, 1, 3, 3)" fillcolor=lightblue]
	140438221738608 -> 140440497203920
	140440497203920 [label=AccumulateGrad]
	140440497203728 -> 140440497203776
	140438221738528 [label="encoder.features.16.conv.1.1.weight
 (960)" fillcolor=lightblue]
	140438221738528 -> 140440497203728
	140440497203728 [label=AccumulateGrad]
	140440497203536 -> 140440497203776
	140438221738688 [label="encoder.features.16.conv.1.1.bias
 (960)" fillcolor=lightblue]
	140438221738688 -> 140440497203536
	140440497203536 [label=AccumulateGrad]
	140440497202768 -> 140443825680304
	140438221739168 [label="encoder.features.16.conv.2.weight
 (160, 960, 1, 1)" fillcolor=lightblue]
	140438221739168 -> 140440497202768
	140440497202768 [label=AccumulateGrad]
	140443825680400 -> 140443893997744
	140438221739248 [label="encoder.features.16.conv.3.weight
 (160)" fillcolor=lightblue]
	140438221739248 -> 140443825680400
	140443825680400 [label=AccumulateGrad]
	140443825682512 -> 140443893997744
	140438221739328 [label="encoder.features.16.conv.3.bias
 (160)" fillcolor=lightblue]
	140438221739328 -> 140443825682512
	140443825682512 [label=AccumulateGrad]
	140443893994528 -> 140443893997168
	140438221739888 [label="encoder.features.17.conv.0.0.weight
 (960, 160, 1, 1)" fillcolor=lightblue]
	140438221739888 -> 140443893994528
	140443893994528 [label=AccumulateGrad]
	140443893989824 -> 140443893994768
	140438221739808 [label="encoder.features.17.conv.0.1.weight
 (960)" fillcolor=lightblue]
	140438221739808 -> 140443893989824
	140443893989824 [label=AccumulateGrad]
	140443893994960 -> 140443893994768
	140438221739968 [label="encoder.features.17.conv.0.1.bias
 (960)" fillcolor=lightblue]
	140438221739968 -> 140443893994960
	140443893994960 [label=AccumulateGrad]
	140443893998176 -> 140438334560320
	140438221740528 [label="encoder.features.17.conv.1.0.weight
 (960, 1, 3, 3)" fillcolor=lightblue]
	140438221740528 -> 140443893998176
	140443893998176 [label=AccumulateGrad]
	140438334564928 -> 140438334565168
	140438221740448 [label="encoder.features.17.conv.1.1.weight
 (960)" fillcolor=lightblue]
	140438221740448 -> 140438334564928
	140438334564928 [label=AccumulateGrad]
	140438334565264 -> 140438334565168
	140438221740608 [label="encoder.features.17.conv.1.1.bias
 (960)" fillcolor=lightblue]
	140438221740608 -> 140438334565264
	140438334565264 [label=AccumulateGrad]
	140438334569728 -> 140438334569584
	140438221741088 [label="encoder.features.17.conv.2.weight
 (320, 960, 1, 1)" fillcolor=lightblue]
	140438221741088 -> 140438334569728
	140438334569728 [label=AccumulateGrad]
	140438334569536 -> 140438334569440
	140438221741168 [label="encoder.features.17.conv.3.weight
 (320)" fillcolor=lightblue]
	140438221741168 -> 140438334569536
	140438334569536 [label=AccumulateGrad]
	140438334569488 -> 140438334569440
	140438221741248 [label="encoder.features.17.conv.3.bias
 (320)" fillcolor=lightblue]
	140438221741248 -> 140438334569488
	140438334569488 [label=AccumulateGrad]
	140438334567856 -> 140438334567712
	140438221741808 [label="encoder.features.18.0.weight
 (1280, 320, 1, 1)" fillcolor=lightblue]
	140438221741808 -> 140438334567856
	140438334567856 [label=AccumulateGrad]
	140438334567664 -> 140438334567616
	140438221741728 [label="encoder.features.18.1.weight
 (1280)" fillcolor=lightblue]
	140438221741728 -> 140438334567664
	140438334567664 [label=AccumulateGrad]
	140438334565792 -> 140438334567616
	140438221741888 [label="encoder.features.18.1.bias
 (1280)" fillcolor=lightblue]
	140438221741888 -> 140438334565792
	140438334565792 [label=AccumulateGrad]
	140438334565888 -> 140438334565984
	140438334566032 -> 140438334564832
	140438221901728 [label="decoder.blocks.0.conv1.0.weight
 (256, 1376, 3, 3)" fillcolor=lightblue]
	140438221901728 -> 140438334566032
	140438334566032 [label=AccumulateGrad]
	140438334564784 -> 140438334564736
	140438221913328 [label="decoder.blocks.0.conv1.1.weight
 (256)" fillcolor=lightblue]
	140438221913328 -> 140438334564784
	140438334564784 [label=AccumulateGrad]
	140438334564496 -> 140438334564736
	140438221908208 [label="decoder.blocks.0.conv1.1.bias
 (256)" fillcolor=lightblue]
	140438221908208 -> 140438334564496
	140438334564496 [label=AccumulateGrad]
	140438334564400 -> 140438334564544
	140438221906048 [label="decoder.blocks.0.conv2.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140438221906048 -> 140438334564400
	140438334564400 [label=AccumulateGrad]
	140438334564352 -> 140438334564256
	140438221905488 [label="decoder.blocks.0.conv2.1.weight
 (256)" fillcolor=lightblue]
	140438221905488 -> 140438334564352
	140438334564352 [label=AccumulateGrad]
	140438334564208 -> 140438334564256
	140438221904768 [label="decoder.blocks.0.conv2.1.bias
 (256)" fillcolor=lightblue]
	140438221904768 -> 140438334564208
	140438334564208 [label=AccumulateGrad]
	140438334564112 -> 140438334563920
	140438334563824 -> 140438334563536
	140438221898608 [label="decoder.blocks.1.conv1.0.weight
 (128, 288, 3, 3)" fillcolor=lightblue]
	140438221898608 -> 140438334563824
	140438334563824 [label=AccumulateGrad]
	140438334563776 -> 140438334563728
	140438221897968 [label="decoder.blocks.1.conv1.1.weight
 (128)" fillcolor=lightblue]
	140438221897968 -> 140438334563776
	140438334563776 [label=AccumulateGrad]
	140438334563872 -> 140438334563728
	140438221897808 [label="decoder.blocks.1.conv1.1.bias
 (128)" fillcolor=lightblue]
	140438221897808 -> 140438334563872
	140438334563872 [label=AccumulateGrad]
	140438334563392 -> 140438334563104
	140438221911648 [label="decoder.blocks.1.conv2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140438221911648 -> 140438334563392
	140438334563392 [label=AccumulateGrad]
	140438334562048 -> 140438334562096
	140438221911408 [label="decoder.blocks.1.conv2.1.weight
 (128)" fillcolor=lightblue]
	140438221911408 -> 140438334562048
	140438334562048 [label=AccumulateGrad]
	140438334560416 -> 140438334562096
	140438221911168 [label="decoder.blocks.1.conv2.1.bias
 (128)" fillcolor=lightblue]
	140438221911168 -> 140438334560416
	140438334560416 [label=AccumulateGrad]
	140438334561952 -> 140438334561856
	140438334560464 -> 140438334563056
	140438221906688 [label="decoder.blocks.2.conv1.0.weight
 (64, 152, 3, 3)" fillcolor=lightblue]
	140438221906688 -> 140438334560464
	140438334560464 [label=AccumulateGrad]
	140438334563008 -> 140438334562960
	140438221905808 [label="decoder.blocks.2.conv1.1.weight
 (64)" fillcolor=lightblue]
	140438221905808 -> 140438334563008
	140438334563008 [label=AccumulateGrad]
	140438334562864 -> 140438334562960
	140438221905008 [label="decoder.blocks.2.conv1.1.bias
 (64)" fillcolor=lightblue]
	140438221905008 -> 140438334562864
	140438334562864 [label=AccumulateGrad]
	140438334565600 -> 140438334559984
	140438221902288 [label="decoder.blocks.2.conv2.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140438221902288 -> 140438334565600
	140438334565600 [label=AccumulateGrad]
	140438334560656 -> 140438334562240
	140438221901888 [label="decoder.blocks.2.conv2.1.weight
 (64)" fillcolor=lightblue]
	140438221901888 -> 140438334560656
	140438334560656 [label=AccumulateGrad]
	140438334567184 -> 140438334562240
	140438221900848 [label="decoder.blocks.2.conv2.1.bias
 (64)" fillcolor=lightblue]
	140438221900848 -> 140438334567184
	140438334567184 [label=AccumulateGrad]
	140438334567088 -> 140438334567952
	140438334561520 -> 140438334562672
	140438221913968 [label="decoder.blocks.3.conv1.0.weight
 (32, 80, 3, 3)" fillcolor=lightblue]
	140438221913968 -> 140438334561520
	140438334561520 [label=AccumulateGrad]
	140438334562576 -> 140438334566752
	140438221913888 [label="decoder.blocks.3.conv1.1.weight
 (32)" fillcolor=lightblue]
	140438221913888 -> 140438334562576
	140438334562576 [label=AccumulateGrad]
	140438334562528 -> 140438334566752
	140438221913728 [label="decoder.blocks.3.conv1.1.bias
 (32)" fillcolor=lightblue]
	140438221913728 -> 140438334562528
	140438334562528 [label=AccumulateGrad]
	140438334569344 -> 140438334560704
	140438221912848 [label="decoder.blocks.3.conv2.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140438221912848 -> 140438334569344
	140438334569344 [label=AccumulateGrad]
	140438334568816 -> 140438334562288
	140438221912768 [label="decoder.blocks.3.conv2.1.weight
 (32)" fillcolor=lightblue]
	140438221912768 -> 140438334568816
	140438334568816 [label=AccumulateGrad]
	140438334569008 -> 140438334562288
	140438221912608 [label="decoder.blocks.3.conv2.1.bias
 (32)" fillcolor=lightblue]
	140438221912608 -> 140438334569008
	140438334569008 [label=AccumulateGrad]
	140438334559216 -> 140438334568240
	140438221911568 [label="decoder.blocks.4.conv1.0.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	140438221911568 -> 140438334559216
	140438334559216 [label=AccumulateGrad]
	140438334562816 -> 140438334566272
	140438221911488 [label="decoder.blocks.4.conv1.1.weight
 (16)" fillcolor=lightblue]
	140438221911488 -> 140438334562816
	140438334562816 [label=AccumulateGrad]
	140438334560608 -> 140438334566272
	140438221911248 [label="decoder.blocks.4.conv1.1.bias
 (16)" fillcolor=lightblue]
	140438221911248 -> 140438334560608
	140438334560608 [label=AccumulateGrad]
	140438334564880 -> 140438334568480
	140438221910208 [label="decoder.blocks.4.conv2.0.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140438221910208 -> 140438334564880
	140438334564880 [label=AccumulateGrad]
	140438334560992 -> 140438334561472
	140438221910128 [label="decoder.blocks.4.conv2.1.weight
 (16)" fillcolor=lightblue]
	140438221910128 -> 140438334560992
	140438334560992 [label=AccumulateGrad]
	140438334566656 -> 140438334561472
	140438221909968 [label="decoder.blocks.4.conv2.1.bias
 (16)" fillcolor=lightblue]
	140438221909968 -> 140438334566656
	140438334566656 [label=AccumulateGrad]
	140438334566368 -> 140438334568960
	140438221909248 [label="segmentation_head.0.weight
 (1, 16, 3, 3)" fillcolor=lightblue]
	140438221909248 -> 140438334566368
	140438334566368 [label=AccumulateGrad]
	140438334562192 -> 140438334568960
	140438221909088 [label="segmentation_head.0.bias
 (1)" fillcolor=lightblue]
	140438221909088 -> 140438334562192
	140438334562192 [label=AccumulateGrad]
	140438334568960 -> 140438221995728
}
